{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87223d00",
   "metadata": {
    "id": "1TFwaJir_Olj",
    "papermill": {
     "duration": 0.005253,
     "end_time": "2025-03-19T16:41:58.515305",
     "exception": false,
     "start_time": "2025-03-19T16:41:58.510052",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# ML2025 Homework 1 - Retrieval Augmented Generation with Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be38ee30",
   "metadata": {
    "id": "6tQHdH2k_Olk",
    "papermill": {
     "duration": 0.004311,
     "end_time": "2025-03-19T16:41:58.524316",
     "exception": false,
     "start_time": "2025-03-19T16:41:58.520005",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239fb623",
   "metadata": {
    "id": "mGx000oZ_Oll",
    "papermill": {
     "duration": 0.00432,
     "end_time": "2025-03-19T16:41:58.533085",
     "exception": false,
     "start_time": "2025-03-19T16:41:58.528765",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In this section, we install the necessary python packages and download model weights of the quantized version of LLaMA 3.1 8B. Also, download the dataset. Note that the model weight is around 8GB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fdc8454",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:41:58.543255Z",
     "iopub.status.busy": "2025-03-19T16:41:58.542958Z",
     "iopub.status.idle": "2025-03-19T16:43:06.516004Z",
     "shell.execute_reply": "2025-03-19T16:43:06.514919Z"
    },
    "id": "5JywoPOO_Oll",
    "papermill": {
     "duration": 67.979985,
     "end_time": "2025-03-19T16:43:06.517661",
     "exception": false,
     "start_time": "2025-03-19T16:41:58.537676",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://abetlen.github.io/llama-cpp-python/whl/cu122\r\n",
      "Collecting llama-cpp-python==0.3.4\r\n",
      "  Downloading https://github.com/abetlen/llama-cpp-python/releases/download/v0.3.4-cu122/llama_cpp_python-0.3.4-cp310-cp310-linux_x86_64.whl (445.2 MB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m445.2/445.2 MB\u001b[0m \u001b[31m298.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.3.4) (4.12.2)\r\n",
      "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.3.4) (1.26.4)\r\n",
      "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.3.4)\r\n",
      "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.3.4) (3.1.4)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.3.4) (3.0.2)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python==0.3.4) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python==0.3.4) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python==0.3.4) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python==0.3.4) (2025.0.1)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python==0.3.4) (2022.0.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.20.0->llama-cpp-python==0.3.4) (2.4.1)\r\n",
      "Requirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20.0->llama-cpp-python==0.3.4) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.20.0->llama-cpp-python==0.3.4) (2022.0.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.20.0->llama-cpp-python==0.3.4) (1.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.20.0->llama-cpp-python==0.3.4) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.20.0->llama-cpp-python==0.3.4) (2024.2.0)\r\n",
      "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: diskcache, llama-cpp-python\r\n",
      "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.4\r\n",
      "Collecting googlesearch-python\r\n",
      "  Downloading googlesearch_python-1.3.0-py3-none-any.whl.metadata (3.4 kB)\r\n",
      "Collecting bs4\r\n",
      "  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\r\n",
      "Requirement already satisfied: charset-normalizer in /usr/local/lib/python3.10/dist-packages (3.4.1)\r\n",
      "Collecting requests-html\r\n",
      "  Downloading requests_html-0.10.0-py3-none-any.whl.metadata (15 kB)\r\n",
      "Collecting lxml_html_clean\r\n",
      "  Downloading lxml_html_clean-0.4.1-py3-none-any.whl.metadata (2.4 kB)\r\n",
      "Requirement already satisfied: beautifulsoup4>=4.9 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (4.12.3)\r\n",
      "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from googlesearch-python) (2.32.3)\r\n",
      "Collecting pyquery (from requests-html)\r\n",
      "  Downloading pyquery-2.0.1-py3-none-any.whl.metadata (9.0 kB)\r\n",
      "Collecting fake-useragent (from requests-html)\r\n",
      "  Downloading fake_useragent-2.1.0-py3-none-any.whl.metadata (17 kB)\r\n",
      "Collecting parse (from requests-html)\r\n",
      "  Downloading parse-1.20.2-py2.py3-none-any.whl.metadata (22 kB)\r\n",
      "Collecting w3lib (from requests-html)\r\n",
      "  Downloading w3lib-2.3.1-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Collecting pyppeteer>=0.0.14 (from requests-html)\r\n",
      "  Downloading pyppeteer-2.0.0-py3-none-any.whl.metadata (7.1 kB)\r\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from lxml_html_clean) (5.3.0)\r\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.9->googlesearch-python) (2.6)\r\n",
      "Collecting appdirs<2.0.0,>=1.4.3 (from pyppeteer>=0.0.14->requests-html)\r\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl.metadata (9.0 kB)\r\n",
      "Requirement already satisfied: certifi>=2023 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (2025.1.31)\r\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (8.5.0)\r\n",
      "Collecting pyee<12.0.0,>=11.0.0 (from pyppeteer>=0.0.14->requests-html)\r\n",
      "  Downloading pyee-11.1.1-py3-none-any.whl.metadata (2.8 kB)\r\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from pyppeteer>=0.0.14->requests-html) (4.67.1)\r\n",
      "Collecting urllib3<2.0.0,>=1.25.8 (from pyppeteer>=0.0.14->requests-html)\r\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hCollecting websockets<11.0,>=10.0 (from pyppeteer>=0.0.14->requests-html)\r\n",
      "  Downloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->googlesearch-python) (3.10)\r\n",
      "Collecting cssselect>=1.2.0 (from pyquery->requests-html)\r\n",
      "  Downloading cssselect-1.3.0-py3-none-any.whl.metadata (2.6 kB)\r\n",
      "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=1.4->pyppeteer>=0.0.14->requests-html) (3.21.0)\r\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pyee<12.0.0,>=11.0.0->pyppeteer>=0.0.14->requests-html) (4.12.2)\r\n",
      "Downloading googlesearch_python-1.3.0-py3-none-any.whl (5.6 kB)\r\n",
      "Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\r\n",
      "Downloading requests_html-0.10.0-py3-none-any.whl (13 kB)\r\n",
      "Downloading lxml_html_clean-0.4.1-py3-none-any.whl (14 kB)\r\n",
      "Downloading pyppeteer-2.0.0-py3-none-any.whl (82 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading fake_useragent-2.1.0-py3-none-any.whl (125 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.8/125.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading parse-1.20.2-py2.py3-none-any.whl (20 kB)\r\n",
      "Downloading pyquery-2.0.1-py3-none-any.whl (22 kB)\r\n",
      "Downloading w3lib-2.3.1-py3-none-any.whl (21 kB)\r\n",
      "Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\r\n",
      "Downloading cssselect-1.3.0-py3-none-any.whl (18 kB)\r\n",
      "Downloading pyee-11.1.1-py3-none-any.whl (15 kB)\r\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading websockets-10.4-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.8/106.8 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: parse, appdirs, websockets, w3lib, urllib3, pyee, lxml_html_clean, fake-useragent, cssselect, pyquery, pyppeteer, bs4, requests-html, googlesearch-python\r\n",
      "  Attempting uninstall: websockets\r\n",
      "    Found existing installation: websockets 14.1\r\n",
      "    Uninstalling websockets-14.1:\r\n",
      "      Successfully uninstalled websockets-14.1\r\n",
      "  Attempting uninstall: urllib3\r\n",
      "    Found existing installation: urllib3 2.3.0\r\n",
      "    Uninstalling urllib3-2.3.0:\r\n",
      "      Successfully uninstalled urllib3-2.3.0\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "google-genai 0.2.2 requires websockets<15.0dev,>=13.0, but you have websockets 10.4 which is incompatible.\r\n",
      "tensorflow-decision-forests 1.10.0 requires tensorflow==2.17.0, but you have tensorflow 2.17.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed appdirs-1.4.4 bs4-0.0.2 cssselect-1.3.0 fake-useragent-2.1.0 googlesearch-python-1.3.0 lxml_html_clean-0.4.1 parse-1.20.2 pyee-11.1.1 pyppeteer-2.0.0 pyquery-2.0.1 requests-html-0.10.0 urllib3-1.26.20 w3lib-2.3.1 websockets-10.4\r\n",
      "--2025-03-19 16:42:20--  https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\r\n",
      "Resolving huggingface.co (huggingface.co)... 3.163.189.114, 3.163.189.74, 3.163.189.90, ...\r\n",
      "Connecting to huggingface.co (huggingface.co)|3.163.189.114|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 302 Found\r\n",
      "Location: https://cdn-lfs-us-1.hf.co/repos/d6/e9/d6e9318f285870e2a0e3056e22f9c7ec90cd13e14cfde122129ae66af9ad788f/9da71c45c90a821809821244d4971e5e5dfad7eb091f0b8ff0546392393b6283?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Meta-Llama-3.1-8B-Instruct-Q8_0.gguf%3B+filename%3D%22Meta-Llama-3.1-8B-Instruct-Q8_0.gguf%22%3B&Expires=1742406140&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MjQwNjE0MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2Q2L2U5L2Q2ZTkzMThmMjg1ODcwZTJhMGUzMDU2ZTIyZjljN2VjOTBjZDEzZTE0Y2ZkZTEyMjEyOWFlNjZhZjlhZDc4OGYvOWRhNzFjNDVjOTBhODIxODA5ODIxMjQ0ZDQ5NzFlNWU1ZGZhZDdlYjA5MWYwYjhmZjA1NDYzOTIzOTNiNjI4Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Rp3%7E2IQoEtchhxqrqhvL9yb46oHvftjmpxNmwuSAur06uG0KkrLUHT44eELW3qQBRBKv31fn-A2iMP-K6bJV9J3ISWuwGVzLLLmYuxzy0laAE4NKN7G1EPDRxpncuy3TTN98Tkksq3E2Nx7B3%7ESbPiPbJENqobB1v-5quX4k%7E1BPCrpv4bhMgNGH8u-F9RQ5WFWdSUCeu37x5IJAT8BN6688ikcVmRlUyXcvpYQl1uGAawMEKo%7EORh16JlS13-aQ0AOp2zNJ0wfVIJ1LSL3O6T3fyVHAoRvAKiSN7GldNadREnvxvJv7QiH1bxD%7E-RTpavl-iFUkOXfJpwdQm-niXQ__&Key-Pair-Id=K24J24Z295AEI9 [following]\r\n",
      "--2025-03-19 16:42:20--  https://cdn-lfs-us-1.hf.co/repos/d6/e9/d6e9318f285870e2a0e3056e22f9c7ec90cd13e14cfde122129ae66af9ad788f/9da71c45c90a821809821244d4971e5e5dfad7eb091f0b8ff0546392393b6283?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Meta-Llama-3.1-8B-Instruct-Q8_0.gguf%3B+filename%3D%22Meta-Llama-3.1-8B-Instruct-Q8_0.gguf%22%3B&Expires=1742406140&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0MjQwNjE0MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zL2Q2L2U5L2Q2ZTkzMThmMjg1ODcwZTJhMGUzMDU2ZTIyZjljN2VjOTBjZDEzZTE0Y2ZkZTEyMjEyOWFlNjZhZjlhZDc4OGYvOWRhNzFjNDVjOTBhODIxODA5ODIxMjQ0ZDQ5NzFlNWU1ZGZhZDdlYjA5MWYwYjhmZjA1NDYzOTIzOTNiNjI4Mz9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=Rp3%7E2IQoEtchhxqrqhvL9yb46oHvftjmpxNmwuSAur06uG0KkrLUHT44eELW3qQBRBKv31fn-A2iMP-K6bJV9J3ISWuwGVzLLLmYuxzy0laAE4NKN7G1EPDRxpncuy3TTN98Tkksq3E2Nx7B3%7ESbPiPbJENqobB1v-5quX4k%7E1BPCrpv4bhMgNGH8u-F9RQ5WFWdSUCeu37x5IJAT8BN6688ikcVmRlUyXcvpYQl1uGAawMEKo%7EORh16JlS13-aQ0AOp2zNJ0wfVIJ1LSL3O6T3fyVHAoRvAKiSN7GldNadREnvxvJv7QiH1bxD%7E-RTpavl-iFUkOXfJpwdQm-niXQ__&Key-Pair-Id=K24J24Z295AEI9\r\n",
      "Resolving cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)... 18.172.170.61, 18.172.170.40, 18.172.170.37, ...\r\n",
      "Connecting to cdn-lfs-us-1.hf.co (cdn-lfs-us-1.hf.co)|18.172.170.61|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 8540775840 (8.0G) [binary/octet-stream]\r\n",
      "Saving to: ‘Meta-Llama-3.1-8B-Instruct-Q8_0.gguf’\r\n",
      "\r\n",
      "Meta-Llama-3.1-8B-I 100%[===================>]   7.95G   206MB/s    in 40s     \r\n",
      "\r\n",
      "2025-03-19 16:43:00 (205 MB/s) - ‘Meta-Llama-3.1-8B-Instruct-Q8_0.gguf’ saved [8540775840/8540775840]\r\n",
      "\r\n",
      "--2025-03-19 16:43:00--  https://www.csie.ntu.edu.tw/~ulin/public.txt\r\n",
      "Resolving www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)... 140.112.30.26\r\n",
      "Connecting to www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)|140.112.30.26|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 4399 (4.3K) [text/plain]\r\n",
      "Saving to: ‘public.txt’\r\n",
      "\r\n",
      "public.txt          100%[===================>]   4.30K  --.-KB/s    in 0s      \r\n",
      "\r\n",
      "2025-03-19 16:43:01 (223 MB/s) - ‘public.txt’ saved [4399/4399]\r\n",
      "\r\n",
      "--2025-03-19 16:43:05--  https://www.csie.ntu.edu.tw/~ulin/private.txt\r\n",
      "Resolving www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)... 140.112.30.26\r\n",
      "Connecting to www.csie.ntu.edu.tw (www.csie.ntu.edu.tw)|140.112.30.26|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 15229 (15K) [text/plain]\r\n",
      "Saving to: ‘private.txt’\r\n",
      "\r\n",
      "private.txt         100%[===================>]  14.87K  --.-KB/s    in 0.1s    \r\n",
      "\r\n",
      "2025-03-19 16:43:06 (122 KB/s) - ‘private.txt’ saved [15229/15229]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m pip install --no-cache-dir llama-cpp-python==0.3.4 --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu122\n",
    "!python3 -m pip install googlesearch-python bs4 charset-normalizer requests-html lxml_html_clean\n",
    "\n",
    "from pathlib import Path\n",
    "if not Path('./Meta-Llama-3.1-8B-Instruct-Q8_0.gguf').exists():\n",
    "    !wget https://huggingface.co/bartowski/Meta-Llama-3.1-8B-Instruct-GGUF/resolve/main/Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\n",
    "if not Path('./public.txt').exists():\n",
    "    !wget https://www.csie.ntu.edu.tw/~ulin/public.txt\n",
    "if not Path('./private.txt').exists():\n",
    "    !wget https://www.csie.ntu.edu.tw/~ulin/private.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b494ca0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:43:06.557283Z",
     "iopub.status.busy": "2025-03-19T16:43:06.557010Z",
     "iopub.status.idle": "2025-03-19T16:43:10.552150Z",
     "shell.execute_reply": "2025-03-19T16:43:10.551099Z"
    },
    "id": "kX6SizAt_Olm",
    "papermill": {
     "duration": 4.015043,
     "end_time": "2025-03-19T16:43:10.553678",
     "exception": false,
     "start_time": "2025-03-19T16:43:06.538635",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are good to go!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "    raise Exception('You are not using the GPU runtime. Change it first or you will suffer from the super slow inference speed!')\n",
    "else:\n",
    "    print('You are good to go!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ac3623",
   "metadata": {
    "id": "l3iyc1qC_Olm",
    "papermill": {
     "duration": 0.016634,
     "end_time": "2025-03-19T16:43:10.587818",
     "exception": false,
     "start_time": "2025-03-19T16:43:10.571184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Prepare the LLM and LLM utility function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3cb9cd6",
   "metadata": {
    "id": "T59vxAo2_Olm",
    "papermill": {
     "duration": 0.016686,
     "end_time": "2025-03-19T16:43:10.621214",
     "exception": false,
     "start_time": "2025-03-19T16:43:10.604528",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "By default, we will use the quantized version of LLaMA 3.1 8B. you can get full marks on this homework by using the provided LLM and LLM utility function. You can also try out different LLM models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b61aaee",
   "metadata": {
    "id": "vtepTeT3_Olm",
    "papermill": {
     "duration": 0.016495,
     "end_time": "2025-03-19T16:43:10.654234",
     "exception": false,
     "start_time": "2025-03-19T16:43:10.637739",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "In the following code block, we will load the downloaded LLM model weights onto the GPU first.\n",
    "Then, we implemented the generate_response() function so that you can get the generated response from the LLM model more easily."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b21116",
   "metadata": {
    "id": "eVil2Vhe_Olm",
    "papermill": {
     "duration": 0.016528,
     "end_time": "2025-03-19T16:43:10.687440",
     "exception": false,
     "start_time": "2025-03-19T16:43:10.670912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "You can ignore \"llama_new_context_with_model: n_ctx_per_seq (16384) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\" warning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eef71c4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:43:10.721727Z",
     "iopub.status.busy": "2025-03-19T16:43:10.721276Z",
     "iopub.status.idle": "2025-03-19T16:43:14.759254Z",
     "shell.execute_reply": "2025-03-19T16:43:14.758580Z"
    },
    "id": "ScyW45N__Olm",
    "papermill": {
     "duration": 4.05684,
     "end_time": "2025-03-19T16:43:14.760779",
     "exception": false,
     "start_time": "2025-03-19T16:43:10.703939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_new_context_with_model: n_ctx_per_seq (16384) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "\n",
    "# Load the model onto GPU\n",
    "llama3 = Llama(\n",
    "    \"./Meta-Llama-3.1-8B-Instruct-Q8_0.gguf\",\n",
    "    verbose=False,\n",
    "    n_gpu_layers=-1,\n",
    "    n_ctx=16384,    # This argument is how many tokens the model can take. The longer the better, but it will consume more memory. 16384 is a proper value for a GPU with 16GB VRAM.\n",
    ")\n",
    "\n",
    "def generate_response(_model: Llama, _messages: str) -> str:\n",
    "    '''\n",
    "    This function will inference the model with given messages.\n",
    "    '''\n",
    "    _output = _model.create_chat_completion(\n",
    "        _messages,\n",
    "        stop=[\"<|eot_id|>\", \"<|end_of_text|>\"],\n",
    "        max_tokens=512,    # This argument is how many tokens the model can generate.\n",
    "        temperature=0,      # This argument is the randomness of the model. 0 means no randomness. You will get the same result with the same input every time. You can try to set it to different values.\n",
    "        repeat_penalty=2.0,\n",
    "    )[\"choices\"][0][\"message\"][\"content\"]\n",
    "    return _output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65db97d3",
   "metadata": {
    "id": "tnHLwq-4_Olm",
    "papermill": {
     "duration": 0.016374,
     "end_time": "2025-03-19T16:43:14.794385",
     "exception": false,
     "start_time": "2025-03-19T16:43:14.778011",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Search Tool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea09a9d",
   "metadata": {
    "id": "SYM-2ZsE_Olm",
    "papermill": {
     "duration": 0.016586,
     "end_time": "2025-03-19T16:43:14.827647",
     "exception": false,
     "start_time": "2025-03-19T16:43:14.811061",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The TA has implemented a search tool for you to search certain keywords using Google Search. You can use this tool to search for the relevant **web pages** for the given question. The search tool can be integrated in the following sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3a19dea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:43:14.861812Z",
     "iopub.status.busy": "2025-03-19T16:43:14.861409Z",
     "iopub.status.idle": "2025-03-19T16:43:15.262506Z",
     "shell.execute_reply": "2025-03-19T16:43:15.261602Z"
    },
    "id": "bEIRmZl7_Oln",
    "papermill": {
     "duration": 0.42,
     "end_time": "2025-03-19T16:43:15.264227",
     "exception": false,
     "start_time": "2025-03-19T16:43:14.844227",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from googlesearch import search as _search\n",
    "from bs4 import BeautifulSoup\n",
    "from charset_normalizer import detect\n",
    "import asyncio\n",
    "from requests_html import AsyncHTMLSession\n",
    "import urllib3\n",
    "urllib3.disable_warnings()\n",
    "\n",
    "async def worker(s:AsyncHTMLSession, url:str):\n",
    "    try:\n",
    "        header_response = await asyncio.wait_for(s.head(url, verify=False), timeout=10)\n",
    "        if 'text/html' not in header_response.headers.get('Content-Type', ''):\n",
    "            return None\n",
    "        r = await asyncio.wait_for(s.get(url, verify=False), timeout=10)\n",
    "        return r.text\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "async def get_htmls(urls):\n",
    "    session = AsyncHTMLSession()\n",
    "    tasks = (worker(session, url) for url in urls)\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "async def search(keyword: str, n_results: int) -> List[str]:\n",
    "    '''\n",
    "    This function will search the keyword and return the text content in the first n_results web pages.\n",
    "    Warning: You may suffer from HTTP 429 errors if you search too many times in a period of time. This is unavoidable and you should take your own risk if you want to try search more results at once.\n",
    "    The rate limit is not explicitly announced by Google, hence there's not much we can do except for changing the IP or wait until Google unban you (we don't know how long the penalty will last either).\n",
    "    '''\n",
    "    keyword = str(keyword)[:100]\n",
    "    # First, search the keyword and get the results. Also, get 2 times more results in case some of them are invalid.\n",
    "    results = list(_search(keyword, n_results * 2, lang=\"zh\", unique=True))\n",
    "    # Then, get the HTML from the results. Also, the helper function will filter out the non-HTML urls.\n",
    "    results = await get_htmls(results)\n",
    "    # Filter out the None values.\n",
    "    results = [x for x in results if x is not None]\n",
    "    # Parse the HTML.\n",
    "    results = [BeautifulSoup(x, 'html.parser') for x in results]\n",
    "    # Get the text from the HTML and remove the spaces. Also, filter out the non-utf-8 encoding.\n",
    "    results = [''.join(x.get_text().split()) for x in results if detect(x.encode()).get('encoding') == 'utf-8']\n",
    "    # Return the first n results.\n",
    "    return results[:n_results]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb05c05",
   "metadata": {
    "id": "rC3zQjjj_Oln",
    "papermill": {
     "duration": 0.016629,
     "end_time": "2025-03-19T16:43:15.298678",
     "exception": false,
     "start_time": "2025-03-19T16:43:15.282049",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Test the LLM inference pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79a92e38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:43:15.333308Z",
     "iopub.status.busy": "2025-03-19T16:43:15.332915Z",
     "iopub.status.idle": "2025-03-19T16:43:23.144500Z",
     "shell.execute_reply": "2025-03-19T16:43:23.143477Z"
    },
    "id": "8dmGCARd_Oln",
    "papermill": {
     "duration": 7.830505,
     "end_time": "2025-03-19T16:43:23.145859",
     "exception": false,
     "start_time": "2025-03-19T16:43:15.315354",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "泰勒絲（Taylor Swift）是一位美國歌手、詞曲作家和音樂製作人。她出生於1989年，來自田納西州。她的音乐风格从乡村乐逐渐转变为流行摇滚，并且她被誉為當代最成功的女艺人的之一。\n",
      "\n",
      "泰勒絲早期在鄉郊小鎮演唱會時開始發展音樂事業，並於2006年發布首張專輯《Taylor Swift》。隨後，她推出了多张专辑，包括 《Fearless》（勇敢）、_Speak Now（說出來）和 _1989 等。她以她的歌曲如 \"Shake It Off\"、\"_Blank Space_\" 和 \"_Bad Blood 》等获得了广泛的认可。\n",
      "\n",
      "泰勒絲也是一位頗具爭議性的藝人，她曾經與多個音樂家發生過創作權和商業糾紛。然而，無論如何她都成為了一代人的偶像，並且她的音乐影響力在全球各地都是非常大的！\n"
     ]
    }
   ],
   "source": [
    "# You can try out different questions here.\n",
    "test_question='請問誰是 Taylor Swift？'\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"你是 LLaMA-3.1-8B，是用來回答問題的 AI。使用中文時只會使用繁體中文來回問題。\"},    # System prompt\n",
    "    {\"role\": \"user\", \"content\": test_question}, # User prompt\n",
    "]\n",
    "\n",
    "print(generate_response(llama3, messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7b9ae1",
   "metadata": {
    "id": "C0-ojJuE_Oln",
    "papermill": {
     "duration": 0.016427,
     "end_time": "2025-03-19T16:43:23.179380",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.162953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57559ed5",
   "metadata": {
    "id": "HGsIPud3_Oln",
    "papermill": {
     "duration": 0.016429,
     "end_time": "2025-03-19T16:43:23.212486",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.196057",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The TA has implemented the Agent class for you. You can use this class to create agents that can interact with the LLM model. The Agent class has the following attributes and methods:\n",
    "- Attributes:\n",
    "    - role_description: The role of the agent. For example, if you want this agent to be a history expert, you can set the role_description to \"You are a history expert. You will only answer questions based on what really happened in the past. Do not generate any answer if you don't have reliable sources.\".\n",
    "    - task_description: The task of the agent. For example, if you want this agent to answer questions only in yes/no, you can set the task_description to \"Please answer the following question in yes/no. Explanations are not needed.\"\n",
    "    - llm: Just an indicator of the LLM model used by the agent.\n",
    "- Method:\n",
    "    - inference: This method takes a message as input and returns the generated response from the LLM model. The message will first be formatted into proper input for the LLM model. (This is where you can set some global instructions like \"Please speak in a polite manner\" or \"Please provide a detailed explanation\".) The generated response will be returned as the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc3c50e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:43:23.246809Z",
     "iopub.status.busy": "2025-03-19T16:43:23.246442Z",
     "iopub.status.idle": "2025-03-19T16:43:23.251355Z",
     "shell.execute_reply": "2025-03-19T16:43:23.250506Z"
    },
    "id": "zjG-UwDX_Oln",
    "papermill": {
     "duration": 0.023522,
     "end_time": "2025-03-19T16:43:23.252720",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.229198",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LLMAgent():\n",
    "    def __init__(self, role_description: str, task_description: str, llm:str=\"bartowski/Meta-Llama-3.1-8B-Instruct-GGUF\"):\n",
    "        self.role_description = role_description   # Role means who this agent should act like. e.g. the history expert, the manager......\n",
    "        self.task_description = task_description    # Task description instructs what task should this agent solve.\n",
    "        self.llm = llm  # LLM indicates which LLM backend this agent is using.\n",
    "    def inference(self, message:str) -> str:\n",
    "        if self.llm == 'bartowski/Meta-Llama-3.1-8B-Instruct-GGUF': # If using the default one.\n",
    "            # TODO: Design the system prompt and user prompt here.\n",
    "            # Format the messsages first.\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": f\"{self.role_description}\"},  # Hint: you may want the agents to speak Traditional Chinese only.\n",
    "                {\"role\": \"user\", \"content\": f\"{self.task_description}\\n{message}\"}, # Hint: you may want the agents to clearly distinguish the task descriptions and the user messages. A proper seperation text rather than a simple line break is recommended.\n",
    "            ]\n",
    "            return generate_response(llama3, messages)\n",
    "        else:\n",
    "            # TODO: If you want to use LLMs other than the given one, please implement the inference part on your own.\n",
    "            return \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1156f9",
   "metadata": {
    "id": "0-ueJrgP_Oln",
    "papermill": {
     "duration": 0.016434,
     "end_time": "2025-03-19T16:43:23.286146",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.269712",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "TODO 1: Design the role description and task description for each agent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3348635",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:43:23.319972Z",
     "iopub.status.busy": "2025-03-19T16:43:23.319732Z",
     "iopub.status.idle": "2025-03-19T16:43:23.323615Z",
     "shell.execute_reply": "2025-03-19T16:43:23.322848Z"
    },
    "id": "DzPzmNnj_Oln",
    "papermill": {
     "duration": 0.022128,
     "end_time": "2025-03-19T16:43:23.324776",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.302648",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO: Design the role and task description for each agent.\n",
    "\n",
    "# This agent may help you filter out the irrelevant parts in question descriptions.\n",
    "question_extraction_agent = LLMAgent(\n",
    "    role_description=\"Extract a concise Google search query from the input text. Retain all key details (names, dates, locations, etc.) while removing extra narrative. \",\n",
    "    task_description=\"Please extract a concise Google search from the following: \",\n",
    ")\n",
    "\n",
    "# Unused\n",
    "# This agent may help you extract the keywords in a question so that the search tool can find more accurate results.\n",
    "keyword_extraction_agent = LLMAgent(\n",
    "    role_description=\"你是 LLaMA-3.1-8B，是從問題描述中找出關鍵詞的 AI。\",\n",
    "    task_description=\"請提取以下描述中的關鍵詞：\",\n",
    ")\n",
    "\n",
    "# Unused\n",
    "abstract_agent = LLMAgent(\n",
    "    role_description=\"你是 LLaMA-3.1-8B，是用來摘要資料的 AI。\",\n",
    "    task_description=\"摘要以下網路資料：\",\n",
    ")\n",
    "\n",
    "# This agent is the core component that answers the question.\n",
    "qa_agent = LLMAgent(\n",
    "    role_description=\"你是 LLaMA-3.1-8B，是根據提供的相關資料回答問題的 AI。\",\n",
    "    task_description=\"請根據提供的相關資料簡要回答問題。\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4123b0e4",
   "metadata": {
    "id": "A9eoywr7_Oln",
    "papermill": {
     "duration": 0.016362,
     "end_time": "2025-03-19T16:43:23.357952",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.341590",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## RAG pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9552d5b7",
   "metadata": {
    "id": "8HDOjNYJ_Oln",
    "papermill": {
     "duration": 0.016381,
     "end_time": "2025-03-19T16:43:23.391002",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.374621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "TODO 2: Implement the RAG pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e85e1ff",
   "metadata": {
    "id": "MRGNa-1i_Oln",
    "papermill": {
     "duration": 0.016583,
     "end_time": "2025-03-19T16:43:23.424235",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.407652",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Please refer to the homework description slides for hints.\n",
    "\n",
    "Also, there might be more heuristics (e.g. classifying the questions based on their lengths, determining if the question need a search or not, reconfirm the answer before returning it to the user......) that are not shown in the flow charts. You can use your creativity to come up with a better solution!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c300b0",
   "metadata": {
    "id": "cMaIsKAZ_Olo",
    "papermill": {
     "duration": 0.016569,
     "end_time": "2025-03-19T16:43:23.457466",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.440897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Naive approach (simple baseline)\n",
    "\n",
    "    ![](https://www.csie.ntu.edu.tw/~ulin/naive.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102cb50e",
   "metadata": {
    "id": "mppO-oOO_Olo",
    "papermill": {
     "duration": 0.016709,
     "end_time": "2025-03-19T16:43:23.491113",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.474404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- Naive RAG approach (medium baseline)\n",
    "\n",
    "    ![](https://www.csie.ntu.edu.tw/~ulin/naive_rag.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aba992cc",
   "metadata": {
    "id": "HYxbciLO_Olo",
    "papermill": {
     "duration": 0.016573,
     "end_time": "2025-03-19T16:43:23.524830",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.508257",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "- RAG with agents (strong baseline)\n",
    "\n",
    "    ![](https://www.csie.ntu.edu.tw/~ulin/rag_agent.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b693d189",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:43:23.560042Z",
     "iopub.status.busy": "2025-03-19T16:43:23.559744Z",
     "iopub.status.idle": "2025-03-19T16:43:23.563595Z",
     "shell.execute_reply": "2025-03-19T16:43:23.562786Z"
    },
    "papermill": {
     "duration": 0.022814,
     "end_time": "2025-03-19T16:43:23.564880",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.542066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def get_refined(question: str) -> str: \n",
    "    refined = question_extraction_agent.inference(question)\n",
    "    refined = refined.split('\"')\n",
    "    if len(refined) > 1:\n",
    "        refined = refined[1]\n",
    "    return refined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b8dadd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:43:23.600416Z",
     "iopub.status.busy": "2025-03-19T16:43:23.600180Z",
     "iopub.status.idle": "2025-03-19T16:43:23.605407Z",
     "shell.execute_reply": "2025-03-19T16:43:23.604646Z"
    },
    "id": "ztJkA7R7_Olo",
    "papermill": {
     "duration": 0.023856,
     "end_time": "2025-03-19T16:43:23.606598",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.582742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "async def pipeline(question: str) -> str:\n",
    "    max_input_len = 7500\n",
    "    search_num = 5\n",
    "\n",
    "    print(f\"[Original Question]: {question}\\n\")\n",
    "    \n",
    "    # Extract the refined question using the question extraction agent\n",
    "    refined_question = await get_refined(question)\n",
    "    print(f\"[Refined Question]: {refined_question}\\n\")\n",
    "    \n",
    "    # Use the search tool to get information based on the extracted keywords\n",
    "    search_results = await search(refined_question, search_num)\n",
    "    for i, result in enumerate(search_results):\n",
    "        result = result[:(max_input_len//search_num)]\n",
    "        search_results[i] = f\"[Search result {i}]: {result}\\n\"\n",
    "    \n",
    "    combined_results = \" \".join(search_results)\n",
    "    \n",
    "    # Combine the refined question with the search results\n",
    "    combined_input = f\"資料: {combined_results}\\n請問: {refined_question}\"\n",
    "    \n",
    "    # Get the final answer from the QA agent\n",
    "    final_answer = qa_agent.inference(combined_input)\n",
    "    print(f\"[Final Answer]: {final_answer}\\n\")\n",
    "\n",
    "    with open('log.txt', 'a') as out_f: \n",
    "        print(f\"[Original Question]: {question}\", file=out_f)\n",
    "        print(f\"[Refined Question]: {refined_question}\", file=out_f)\n",
    "        for srch in search_results:\n",
    "            print(f\"[Search Result]: {srch}\", file=out_f)\n",
    "        print(f\"[Answer]: {final_answer}\", file=out_f)\n",
    "    \n",
    "    return final_answer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4ed5b4",
   "metadata": {
    "id": "P_kI_9EGB0S9",
    "papermill": {
     "duration": 0.016493,
     "end_time": "2025-03-19T16:43:23.639642",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.623149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Answer the questions using your pipeline!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74d4ea39",
   "metadata": {
    "id": "PN17sSZ8DUg7",
    "papermill": {
     "duration": 0.016572,
     "end_time": "2025-03-19T16:43:23.672876",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.656304",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Since Colab has usage limit, you might encounter the disconnections. The following code will save your answer for each question. If you have mounted your Google Drive as instructed, you can just rerun the whole notebook to continue your process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0746f77e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T16:43:23.707138Z",
     "iopub.status.busy": "2025-03-19T16:43:23.706861Z",
     "iopub.status.idle": "2025-03-19T17:11:54.125352Z",
     "shell.execute_reply": "2025-03-19T17:11:54.124318Z"
    },
    "id": "plUDRTi_B39S",
    "papermill": {
     "duration": 1710.462848,
     "end_time": "2025-03-19T17:11:54.152332",
     "exception": false,
     "start_time": "2025-03-19T16:43:23.689484",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Original Question]: 校歌為學校（包括小學、中學、大學等）宣告或者規定的代表該校的歌曲。用於體現該校的治學理念、辦學理想等學校文化。「虎山雄風飛揚」是哪間學校的校歌歌詞？\n",
      "\n",
      "[Refined Question]: 虎山雄風飛揚 校歌 歌詞\n",
      "\n",
      "[Final Answer]: 根據提供的資料，虎山雄風飛揚是光華國小校歌的一部分。以下是一些相關內容：\n",
      "\n",
      "貓羅溪旁\n",
      "　 虎 山 雄 風 飛 揮\n",
      "\n",
      "這兒是我們生長的地方\n",
      "\n",
      "1 根據提供的資料，虎山雄風飛揚是光華國小校歌的一部分。以下是一些相關內容：  貓羅溪旁 　 虎 山 雄 風 飛 揮  這兒是我們生長的地方\n",
      "[Original Question]: 2025年初，NCC透過行政命令，規定民眾如果透過境外郵購無線鍵盤、滑鼠、藍芽耳機..等自用產品回台，每案一律加收審查費多少錢？\n",
      "\n",
      "[Refined Question]: NCC 2025年初境外郵購自用產品審查費\n",
      "\n",
      "[Final Answer]: 根據提供的資料，NCC於2025年2月初實施新規定，由于民眾網購國外自用的「第二級電信管制射頻器材」，並以郵寄方式進入台灣，每件商品需繳納750元審查費。\n",
      "\n",
      "2 根據提供的資料，NCC於2025年2月初實施新規定，由于民眾網購國外自用的「第二級電信管制射頻器材」，並以郵寄方式進入台灣，每件商品需繳納750元審查費。\n",
      "[Original Question]: 第一代 iPhone 是由哪位蘋果 CEO 發表？\n",
      "\n",
      "[Refined Question]: 第一代 iPhone 由哪位苹果 CEO 发表\n",
      "\n",
      "[Final Answer]: 第一代 iPhone 由史蒂夫·乔布斯（Steve Jobs）在 2007 年的 Macworld Conference & Expo 发表。\n",
      "\n",
      "3 第一代 iPhone 由史蒂夫·乔布斯（Steve Jobs）在 2007 年的 Macworld Conference & Expo 发表。\n",
      "[Original Question]: 台灣大學進階英文免修申請規定中，托福網路測驗 TOEFL iBT 要達到多少分才能申請？\n",
      "\n",
      "[Refined Question]: 台灣大學進階英文免修托福網路測驗分數要求\n",
      "\n",
      "[Final Answer]: 根據提供的資料，台大進階英文免修申請系統並未明確提及托福網路測驗分數要求。\n",
      "\n",
      "4 根據提供的資料，台大進階英文免修申請系統並未明確提及托福網路測驗分數要求。\n",
      "[Original Question]: Rugby Union 中觸地 try 可得幾分？\n",
      "\n",
      "[Refined Question]: Rugby Union 地球觸地 try 得分多少\n",
      "\n",
      "[Final Answer]: 根據橄榉球規則，當一名選手觸地並將足球推進到對方的得分區內時，就會獲得一個試煞（Try），而這個嘗试成功後，可以得到五點。\n",
      "\n",
      "因此，在Rugby Union中，一次Touchdown (地球触底) 得到的 Try 分數是 5 默。\n",
      "\n",
      "5 根據橄榉球規則，當一名選手觸地並將足球推進到對方的得分區內時，就會獲得一個試煞（Try），而這個嘗试成功後，可以得到五點。  因此，在Rugby Union中，一次Touchdown (地球触底) 得到的 Try 分數是 5 默。\n",
      "[Original Question]: 卑南族是位在臺東平原的一個原住民族，以驍勇善戰、擅長巫術聞名，曾經統治整個臺東平原。相傳卑南族的祖先發源自 ruvuwa'an，該地位於現今的哪個行政區劃？\n",
      "\n",
      "[Refined Question]: 卑南族祖先 ruvuwa'an 行政區劃\n",
      "\n",
      "[Final Answer]: 根據提供的資料，卑南族祖先 Ruvoawan 的故事如下：\n",
      "\n",
      "Ruvoa'an 是一座海岸地點，在 Revuwa'a'n 海邊出現了石頭，這些 stone 被認為是人類始源。這個傳說中提到，一對男女從竹子裡生下來，分別叫做 Pagumalay 和 Pagsir。\n",
      "\n",
      "Ruvoa'an 還被描述成一座山坡地點，在 Revuwa'a'n 海邊出現了石頭，這些 stone 被認為是人類始源。這個傳說中提到，一對男女從竹子裡生下來，分別叫做 Pagumalay 和 Pagsir。\n",
      "\n",
      "根據資料，我們可以知道卑南族祖先 Ruvoawan 的故事與石頭和山坡地點有關，並且被認為是人類始源。\n",
      "\n",
      "6 根據提供的資料，卑南族祖先 Ruvoawan 的故事如下：  Ruvoa'an 是一座海岸地點，在 Revuwa'a'n 海邊出現了石頭，這些 stone 被認為是人類始源。這個傳說中提到，一對男女從竹子裡生下來，分別叫做 Pagumalay 和 Pagsir。  Ruvoa'an 還被描述成一座山坡地點，在 Revuwa'a'n 海邊出現了石頭，這些 stone 被認為是人類始源。這個傳說中提到，一對男女從竹子裡生下來，分別叫做 Pagumalay 和 Pagsir。  根據資料，我們可以知道卑南族祖先 Ruvoawan 的故事與石頭和山坡地點有關，並且被認為是人類始源。\n",
      "[Original Question]: 熊信寬，藝名熊仔，是臺灣饒舌創作歌手。2022年獲得第33屆金曲獎最佳作詞人獎，2023年獲得第34屆金曲獎最佳華語專輯獎。請問熊仔的碩班指導教授為？\n",
      "\n",
      "[Refined Question]: 熊仔碩班指導教授\n",
      "\n",
      "[Final Answer]: 根據提供的資料，熊仔碩班指導教授是李琳山。\n",
      "\n",
      "7 根據提供的資料，熊仔碩班指導教授是李琳山。\n",
      "[Original Question]: 請問誰發現了電磁感應定律，並奠定了電磁學的重要基礎？\n",
      "\n",
      "[Refined Question]: 誰發現了電磁感應定律\n",
      "\n",
      "[Final Answer]: 法拉第是發現了電磁感應定律的人。\n",
      "\n",
      "8 法拉第是發現了電磁感應定律的人。\n",
      "[Original Question]: 臺灣東部第一座國家級博物館—「國立臺灣史前文化博物館」，源自於卑南文化遺址的發現。博物館擁有世界級建築設計與豐富的展品。請問距離國立臺灣史前文化博物館最近的臺鐵車站為？\n",
      "\n",
      "[Refined Question]: 國立臺灣史前文化博物館最近的臺鐵車站\n",
      "\n",
      "[Final Answer]: 根據提供的資料，國立臺灣史前文化博物館最近的大台鐵車站是康樂本局。\n",
      "\n",
      "9 根據提供的資料，國立臺灣史前文化博物館最近的大台鐵車站是康樂本局。\n",
      "[Original Question]: 20+30=?\n",
      "\n",
      "[Refined Question]: math problems involving addition\n",
      "\n",
      "[Final Answer]: 根據提供的相關資料，我們可以找到以下與加法題目（math problems involving addition）有關的一些資源：\n",
      "\n",
      "1. AdditionWorksheets：這是一個網站，內容包括各種類型的小學生喜歡用的數字運算練習紙。\n",
      "2.[Search result 0] 中提到 \"Addition Facts Tables\" 和一些其他與加法相關的題目，如 Five Minute Additions Frenzies、Single-Digit Addition 等。\n",
      "\n",
      "這些資源可以幫助您找到適合您的學生的數字運算練習紙和問題。\n",
      "\n",
      "10 根據提供的相關資料，我們可以找到以下與加法題目（math problems involving addition）有關的一些資源：  1. AdditionWorksheets：這是一個網站，內容包括各種類型的小學生喜歡用的數字運算練習紙。 2.[Search result 0] 中提到 \"Addition Facts Tables\" 和一些其他與加法相關的題目，如 Five Minute Additions Frenzies、Single-Digit Addition 等。  這些資源可以幫助您找到適合您的學生的數字運算練習紙和問題。\n",
      "[Original Question]: 在NBA 2025年的交易大限前，達拉斯獨行俠隊的當家球星Luka Doncic被交易至聯盟中的哪一隊？\n",
      "\n",
      "[Refined Question]: Luka Doncic 2025 NBA trade deadline\n",
      "\n",
      "[Final Answer]: 根據提供的資料，Luka Doncic 在 2025 NBA 貿易截止日被交易到 Los Angeles Lakers。\n",
      "\n",
      "11 根據提供的資料，Luka Doncic 在 2025 NBA 貿易截止日被交易到 Los Angeles Lakers。\n",
      "[Original Question]: 請問2024年美國總統大選的勝選人是誰？\n",
      "\n",
      "[Refined Question]: 2024年美國總統大選勝选人是誰\n",
      "\n",
      "[Final Answer]: 根據提供的資料，2024年美國總統大選勝选人是唐纳德·特朗普（Donald Trump）。\n",
      "\n",
      "12 根據提供的資料，2024年美國總統大選勝选人是唐纳德·特朗普（Donald Trump）。\n",
      "[Original Question]: Meta 的 Llama-3.2 系列模型中，參數量最小的模型是多少 Billion 的參數？\n",
      "\n",
      "[Refined Question]: Meta Llama-3.2 model parameter size in billions\n",
      "\n",
      "[Final Answer]: 根據 Search result 2 的資料，Meta Llama-3.1 model parameter size 在 billions 中為：\n",
      "\n",
      "* 小型視覺模型 (11B)\n",
      "* 大規模文本模式（90億）\n",
      " \n",
      "但是Search Result中沒有提到Llamamodel的參數大小。\n",
      "\n",
      "13 根據 Search result 2 的資料，Meta Llama-3.1 model parameter size 在 billions 中為：  * 小型視覺模型 (11B) * 大規模文本模式（90億）   但是Search Result中沒有提到Llamamodel的參數大小。\n",
      "[Original Question]: 停修是指在學期中，學生因為各式因素認為無法繼續修習某一門課時，可以向學校申請停修。與學期初選課退選不同，停修有更嚴格的限制。依據國立臺灣大學學則，在沒有學生報告書的情況下，學生每學期至多停修幾門課程？\n",
      "\n",
      "[Refined Question]: 國立臺灣大學停修限制每學期門課程數量\n",
      "\n",
      "[Final Answer]: 根據提供的資料，國立臺灣大學停修限制每學期最多可申請1門課程。\n",
      "\n",
      "14 根據提供的資料，國立臺灣大學停修限制每學期最多可申請1門課程。\n",
      "[Original Question]: DeepSeek公司的母公司是？\n",
      "\n",
      "[Refined Question]: DeepSeek公司的母 公司是？\n",
      "\n",
      "[Final Answer]: DeepSeek的母公司是幻方量化（High-Flyer）。\n",
      "\n",
      "15 DeepSeek的母公司是幻方量化（High-Flyer）。\n",
      "[Original Question]: 2024年NBA的總冠軍隊伍是哪一隊？\n",
      "\n",
      "[Refined Question]: 2024年NBA總冠軍隊伍是哪一队\n",
      "\n",
      "[Final Answer]: 根據資料，2024年NBA總冠軍隊伍是波士頓凱爾特人（Boston Celtics）。\n",
      "\n",
      "16 根據資料，2024年NBA總冠軍隊伍是波士頓凱爾特人（Boston Celtics）。\n",
      "[Original Question]: 一個碳氫化合物分子中有碳原子與碳原子形成三鍵，此類化合物稱為什麼？\n",
      "\n",
      "[Refined Question]: 什麼是碳原子三鍵化合物\n",
      "\n",
      "[Final Answer]: 根據提供的資料，碳原子三鍵化合物是指兩個或多於二个 碲 原子的共价键，其中每一個 鍾 項 都有 三 個電子。\n",
      "\n",
      "17 根據提供的資料，碳原子三鍵化合物是指兩個或多於二个 碲 原子的共价键，其中每一個 鍾 項 都有 三 個電子。\n",
      "[Original Question]: 請問被譽為「計算機科學之父」，提出圖靈機概念、為現代計算理論奠定基礎的人是誰？\n",
      "\n",
      "[Refined Question]: 計算機科學之父圖靈机概念提出者\n",
      "\n",
      "[Final Answer]: 艾伦·图灵\n",
      "\n",
      "18 艾伦·图灵\n",
      "[Original Question]: 手持七星劍、披髮赤足、腳踏蛇龜的玄天上帝，俗稱為「上帝公、上帝爺公、上帝爺、帝爺公」，據傳是北極玄武星君之化身，擁有消災解厄的神力。臺灣玄天上帝信仰的進香中心位於哪個行政區劃內？請回答縣市及鄉鎮市區。\n",
      "\n",
      "[Refined Question]: 臺灣玄天上帝信仰進香中心行政區劃縣市鄉鎮\n",
      "\n",
      "[Final Answer]: 根據提供的資料，臺灣玄天上帝信仰進香中心松柏嶺受天堂位於南投縣名間鄉。\n",
      "\n",
      "19 根據提供的資料，臺灣玄天上帝信仰進香中心松柏嶺受天堂位於南投縣名間鄉。\n",
      "[Original Question]: Windows 作業系統是哪間科技公司的產品？\n",
      "\n",
      "[Refined Question]: Windows 作業系統是哪間科技公司的產品\n",
      "\n",
      "[Final Answer]: Windows 作業系統是微軟公司的產品。\n",
      "\n",
      "20 Windows 作業系統是微軟公司的產品。\n",
      "[Original Question]: 官將首，是一種傳統信仰文化的陣頭，經常被大眾與八家將混淆。八家將是經由福州傳衍來臺，而官將首是臺灣所創立，主要任務都是擔任主神的駕前侍衛，在迎神活動中負責保護主神、押煞之職能。請問官將首起源自哪間廟宇？\n",
      "\n",
      "[Refined Question]: 官將首起源自哪間廟宇\n",
      "\n",
      "[Final Answer]: 官將首起源自新莊地藏庵。\n",
      "\n",
      "21 官將首起源自新莊地藏庵。\n",
      "[Original Question]: 臺灣電影《咒》講述一位單親媽媽受邪神詛咒的故事。邪神一詞常用来形容邪惡的神靈或力量，常被比喻為邪惡勢力或具有破壞性、危險性的人或事物。請問《咒》的邪神名為？\n",
      "\n",
      "[Refined Question]: 《咒》邪神名為？\n",
      "\n",
      "[Final Answer]: 《咒》邪神名為「大黑佛母」。\n",
      "\n",
      "22 《咒》邪神名為「大黑佛母」。\n",
      "[Original Question]: 「如果你朋友唱歌沒有跑調，一定是他的伴侶跑掉了」是一句用來形容失戀之人唱歌模樣的網路笑話。「短暫交會的旅程就此分岔」是哪個歌唱團體歌曲中的歌詞？\n",
      "\n",
      "[Refined Question]: ['一個可能的Google搜尋是：\\n\\n「短暫交會旅程歌詞」']\n",
      "\n",
      "[Final Answer]: 根據資料，我們可以推測你想要知道的是「短暫交會旅程」的歌詞。\n",
      "\n",
      "23 根據資料，我們可以推測你想要知道的是「短暫交會旅程」的歌詞。\n",
      "[Original Question]: 卑南族是臺灣的一個原住民族，除了每年年底的各部落各自舉辦的年祭之外，每兩年卑南族十個部落會輪流舉辦聯合年聚，以凝聚各部落間的感情。請問 2025 卑南族聯合年聚在哪個部落舉辦？\n",
      "\n",
      "[Refined Question]: 2025 卑南族聯合年聚舉辦地點\n",
      "\n",
      "[Final Answer]: 根據資料，2025 卑南族聯合年聚將於2月1日（大年的初四）在台東縣利嘉部落的Likavung 利卡夢國小舉辦。\n",
      "\n",
      "24 根據資料，2025 卑南族聯合年聚將於2月1日（大年的初四）在台東縣利嘉部落的Likavung 利卡夢國小舉辦。\n",
      "[Original Question]: 最新的輝達顯卡是出到「GeForce RTX 多少」系列？\n",
      "\n",
      "[Refined Question]: GeForce RTX 多少系列最新顯卡\n",
      "\n",
      "[Final Answer]: 根據提供的資料，GeForce RTX 最新系列顯卡是 GeForceRTXT50 系列。\n",
      "\n",
      "25 根據提供的資料，GeForce RTX 最新系列顯卡是 GeForceRTXT50 系列。\n",
      "[Original Question]: 藝人大S是在去哪個國家旅遊時因病去世？\n",
      "\n",
      "[Refined Question]: 大S去哪個國家旅遊時因病過世\n",
      "\n",
      "[Final Answer]: 大S去日本旅遊時因病過世。\n",
      "\n",
      "26 大S去日本旅遊時因病過世。\n",
      "[Original Question]: 是誰發現了萬有引力？\n",
      "\n",
      "[Refined Question]: 萬有引力發現者是誰\n",
      "\n",
      "[Final Answer]: 根據提供的資料，萬有引力的發現者是艾萨克·牛顿（Isaac Newton）。\n",
      "\n",
      "27 根據提供的資料，萬有引力的發現者是艾萨克·牛顿（Isaac Newton）。\n",
      "[Original Question]: 台鵠開示計畫「TAIHUCAIS」的英文全名為何？\n",
      "\n",
      "[Refined Question]: TAIHUCAIS 英文全名\n",
      "\n",
      "[Final Answer]: 根據提供的資料，我們無法直接找到 TAIHUCAIS 的英文全名。\n",
      "\n",
      "28 根據提供的資料，我們無法直接找到 TAIHUCAIS 的英文全名。\n",
      "[Original Question]: 「I'll be back」是出自哪部電影的經典台詞？\n",
      "\n",
      "[Refined Question]: [\"A concise Google search query for the input text would be:\\n\\n「I'll Be Back經典台詞」\"]\n",
      "\n",
      "[Final Answer]: 你可以使用以下的Google搜尋查詢:\n",
      "\n",
      "「I'll Be Back經典台詞」\n",
      "\n",
      "29 你可以使用以下的Google搜尋查詢:  「I'll Be Back經典台詞」\n",
      "[Original Question]: 水的化學式為？\n",
      "\n",
      "[Refined Question]: 水的化學式為?\n",
      "\n",
      "[Final Answer]: 水的化學式為H2O。\n",
      "\n",
      "30 水的化學式為H2O。\n",
      "[Original Question]: 李宏毅（Hung-yi Lee）是台灣著名的人工智慧與機器學習領域的學者，現任教於國立台灣大學電機工程學系。他是台灣大學的教授，也是該校人工智慧研究的領軍人物之一，尤其在機器學習、深度學習和語音處理領域具有深遠的影響。李宏毅教授在學術界的貢獻涵蓋了許多技術領域，特別是在語音處理、自然語言處理方面。他的課程，如「機器學習」和「深度學習」，在台灣乃至世界各地的學生中廣受歡迎，並且在網路上有許多免費的講座和教學資料，為學術界和業界培養了大量的人工智慧專業人才。李教授的研究興趣主要集中在深度學習的各種應用上，包括語音處理、視覺理解、生成模型等。他的學術成就不僅在學術論文上有所體現，還積極推動機器學習技術在實際生活中的應用。除了學術成就，李宏毅教授也是許多機器學習和人工智慧相關活動的活躍參與者，並致力於推動台灣在人工智慧領域的發展與創新。他的教學風格深入淺出，善於將複雜的理論問題以簡單明瞭的方式呈現，因此深受學生的喜愛。那李宏毅在台灣大學開設的《機器學習》 2023 年春季班中，第15個作業的名稱是什麼？\n",
      "\n",
      "\n",
      "[Refined Question]: 李宏毅 台大 機器學習 2023 春季班 第15個作業名稱\n",
      "\n",
      "[Final Answer]: 根據提供的資料，我們可以看到李宏毅 台大 機器學習 2023 春季班 的作業列表如下：\n",
      "\n",
      "1. 作业01: 回归 (COVID-19 Cases Prediction)\n",
      "2. acted homework13~15\n",
      "   HW14 \n",
      "    https://ntuccoocool.ntu.edu.tw/course/ml23/hw/README.md\n",
      "\n",
      "31 根據提供的資料，我們可以看到李宏毅 台大 機器學習 2023 春季班 的作業列表如下：  1. 作业01: 回归 (COVID-19 Cases Prediction) 2. acted homework13~15    HW14      https://ntuccoocool.ntu.edu.tw/course/ml23/hw/README.md\n",
      "[Original Question]: 目前臺灣多數獨立學院皆已升格為大學，公立的獨立學院僅剩一間，請問該獨立學院為何？\n",
      "\n",
      "\n",
      "[Refined Question]: 臺灣公立獨 立學院名單\n",
      "\n",
      "[Final Answer]: 根據提供的資料，以下是臺灣公立獨 立學院名單：\n",
      "\n",
      "1. 國防管理学院（國軍官校）\n",
      "2..\n",
      "\n",
      "32 根據提供的資料，以下是臺灣公立獨 立學院名單：  1. 國防管理学院（國軍官校） 2..\n",
      "[Original Question]: BitTorrent 協議曾經在臺灣掀起一陣盜版影音的歪風，該協議運用何種機制來確保當一個新的節點加入網路，尚無任何 chunk 時，也能從其他種子隨機地獲得部分資料，以利其後續整個網路的資料交換？\n",
      "\n",
      "\n",
      "[Refined Question]: BitTorrent 協議節點加入網路機制\n",
      "\n",
      "[Final Answer]: 根據提供的資料，BitTorrent 協議節點加入網路機制如下：\n",
      "\n",
      "1. 生成種子文件 (.torrent)：發布者會將要分享檔回傳一個.torrent 檢索器，這個檢 細是包含了 Tracker 資訊和 File 訊息兩部分。\n",
      "2.. torrent 文件解析: BT 客户端首先会对 .torren t 信息进行分析，获取Tracker 地址，然后连接到该地址的tracker服务器。 \n",
      "3. tracker服务 器回应请求：当BT客户机向 Tracker 请求时，它们将提供其他下载者（包括发布者的）IP给予下載機。\n",
      "4.. torrent 文件中包含了一个名为“announce”的字段，这个值是Tracker 服務器地址，通过这个连接，可以获取到种子文件的信息和tracker服务 器列表。 \n",
      "5. BT 客户端会将 .torrent 檢索中的 Tracker 地址传递给 tracker服务器。\n",
      "6.. torrent 文件中包含了一个名为“announce”的字段，这个值是Tracker 服務器地址，通过这个连接，可以获取到种子文件的信息和tracker服务 器列表。 \n",
      "7. BT 客户端会将 .torrent 檢索中的 Tracker 地址传递给 tracker服务器。\n",
      "8.. torrent 文件中包含了一个名为“announce”的字段，这个值是Tracker 服務器地址，通过这个连接，可以获取到种子文件的信息和tracker服务 器列表。 \n",
      "9. BT 客户端会将 .torrent 檢索中的 Tracker 地址传递给 tracker服务器。\n",
      "10.. torrent 文件中包含了一个名为“announce”的字段，这个值是Tracker 服務器地址，通过这个连接，可以获取到种子文件的信息和tracker服务 器列表。 \n",
      "11. BT 客户端会将 .torrent 檢索中的 Tracker 地址传递给 tracker服务器。\n",
      "12.. torrent 文件中包含了一个名为“announce”的字段，这个值是Tracker 服務器地址，通过这个连接，可以获取到种子文件的信息和tracker服务 器列表。 \n",
      "13. BT 客户端会将 .torrent 檢索中的 Tracker 地址传递给 tracker服务器。\n",
      "14.. torrent 文件中包含了一个名为“announce”的字段，这个值是Tracker 服務器地址，通过这个连接，可以获取到种子文件\n",
      "\n",
      "33 根據提供的資料，BitTorrent 協議節點加入網路機制如下：  1. 生成種子文件 (.torrent)：發布者會將要分享檔回傳一個.torrent 檢索器，這個檢 細是包含了 Tracker 資訊和 File 訊息兩部分。 2.. torrent 文件解析: BT 客户端首先会对 .torren t 信息进行分析，获取Tracker 地址，然后连接到该地址的tracker服务器。  3. tracker服务 器回应请求：当BT客户机向 Tracker 请求时，它们将提供其他下载者（包括发布者的）IP给予下載機。 4.. torrent 文件中包含了一个名为“announce”的字段，这个值是Tracker 服務器地址，通过这个连接，可以获取到种子文件的信息和tracker服务 器列表。  5. BT 客户端会将 .torrent 檢索中的 Tracker 地址传递给 tracker服务器。 6.. torrent 文件中包含了一个名为“announce”的字段，这个值是Tracker 服務器地址，通过这个连接，可以获取到种子文件的信息和tracker服务 器列表。  7. BT 客户端会将 .torrent 檢索中的 Tracker 地址传递给 tracker服务器。 8.. torrent 文件中包含了一个名为“announce”的字段，这个值是Tracker 服務器地址，通过这个连接，可以获取到种子文件的信息和tracker服务 器列表。  9. BT 客户端会将 .torrent 檢索中的 Tracker 地址传递给 tracker服务器。 10.. torrent 文件中包含了一个名为“announce”的字段，这个值是Tracker 服務器地址，通过这个连接，可以获取到种子文件的信息和tracker服务 器列表。  11. BT 客户端会将 .torrent 檢索中的 Tracker 地址传递给 tracker服务器。 12.. torrent 文件中包含了一个名为“announce”的字段，这个值是Tracker 服務器地址，通过这个连接，可以获取到种子文件的信息和tracker服务 器列表。  13. BT 客户端会将 .torrent 檢索中的 Tracker 地址传递给 tracker服务器。 14.. torrent 文件中包含了一个名为“announce”的字段，这个值是Tracker 服務器地址，通过这个连接，可以获取到种子文件\n",
      "[Original Question]: 前幾天聽朋友在滑youtube的影片，說看到一個人用英文跟另一個騎著摩托車的人說要去某某大學能不能載他一程，騎摩托車的人馬上說一聲sure答應了請求，並說甚麼go back go back要他上車，結果出發後沒幾秒就摔車了。那個是甚麼影片阿？\n",
      "\n",
      "\n",
      "[Refined Question]: youtube video sure go back motorcycle accident university pickup\n",
      "\n",
      "[Final Answer]: 根據提供的資料，我們無法找到與 \"youtube video sure go back motorcycle accident university pickup\" 相關聯結。\n",
      "\n",
      "34 根據提供的資料，我們無法找到與 \"youtube video sure go back motorcycle accident university pickup\" 相關聯結。\n",
      "[Original Question]: 根據許多來自各方的觀察報告以及相關研究資料顯示，研究人員在奧地利維也納大學獸醫學院中，十分驚奇地且仔細地發現，戈芬氏鳳頭鸚鵡（亦稱為Goffin's cockatoo）竟然會將食物浸入乳酪之中，以期能夠提升口感與風味。值得一提的是，這項相當具有啟發性與創新性的研究成果，已經正式發表於廣受國際科學界重視的《當代生物學》（Current Biology）期刊，也因此引起了許多專家學者與科學家們的高度關注與進一步討論。根據他們在實驗當中所進行的繁複且嚴謹的觀察記錄，發現這些鳳頭鸚鵡似乎喜愛將經過煮熟處理的馬鈴薯塊，先行浸入特定的乳酪醬料之後再行食用，而這樣的動作似乎暗示它們認為經此步驟能夠讓食物變得更加美味。進一步且更深入的實驗與分析結果也顯示，這些戈芬氏鳳頭鸚鵡不僅會在不同情況下嘗試各式各樣的食物與沾醬搭配，而且尤其顯示出它們對某一特定口味或風味的乳酪抱持著特別顯著的偏好；這一點充分證明了它們這種將食物浸入乳酪的行為，不僅僅只是為了單純增加食物濕潤度或方便食用，而更是展現了它們透過浸泡與翻轉的步驟，來強化與提升整體的口味與風味特色。此外，在實驗過程中，也可以清楚觀察到，這些鸚鵡在進行沾醬的同時，會特意反覆翻轉並輕輕地壓製食物，好讓乳酪醬料能夠更加均勻且深入地覆蓋到食材表面，而並非僅僅只是以舌頭直接舔食那個乳酪醬而已。從中我們也看出它們對食材與醬料之間的配合度，以及口感層次的提升，具有一定程度的講究與偏好。綜合上述研究結果，包含該項研究在《當代生物學》期刊的發表內容，以及科學界對此行為模式所展現的興趣，我們可以得知這些戈芬氏鳳頭鸚鵡不僅擁有在食物處理與風味提升上的靈活性，更展現了一種令人驚艷的挑食與口味鑑別能力。因此，在這些看似豐富而又極具趣味性的發現背後，我們也不禁要進一步提出疑問：既然它們會特別挑選某種口味的乳酪來提升風味，那麼究竟在這些眾多多元且可能性豐富的乳酪口味當中，最終令戈芬氏鳳頭鸚鵡展現出顯著偏好的口味是哪一種呢？換句話說，請問在這整個實驗結果中，最受這些鸚鵡偏好且深具吸引力的乳酪口味到底是什麼呢？\n",
      "\n",
      "\n",
      "[Refined Question]: Goffin's cockatoo 食物乳酪口味風格偏好研究奧地利維也納大學獸醫學院《當代生物學》期刊\n",
      "\n",
      "[Final Answer]: 根據資料，我們可以知道 Goffin's cockatoo 食物乳酪口味風格偏好研究的相關資訊如下：\n",
      "\n",
      "* 研究地點：奧西亞（Austria）\n",
      "  * 其實是指維也納大學獸醫學院\n",
      "    (University of Veterinary Medicine Vienna)\n",
      " \n",
      "這個資料可能與《當代生物學》期刊有關，但具體內容我無法提供。\n",
      "\n",
      "35 根據資料，我們可以知道 Goffin's cockatoo 食物乳酪口味風格偏好研究的相關資訊如下：  * 研究地點：奧西亞（Austria）   * 其實是指維也納大學獸醫學院     (University of Veterinary Medicine Vienna)   這個資料可能與《當代生物學》期刊有關，但具體內容我無法提供。\n",
      "[Original Question]: 2024年，住在桃園Xpark水族館的國王企鵝「嘟胖」以及「烏龍茶」順利產下一隻企鵝寶寶，Xpark也因此於網路上舉行了企鵝命名的投稿和名稱投票活動，最後這隻企鵝寶寶的名子是？\n",
      "\n",
      "\n",
      "[Refined Question]: 嘟胖烏龍茶企鵝寶貝名字投票2024年桃園Xpark水族館\n",
      "\n",
      "[Final Answer]: 根據資料，嘟胖烏龍茶企鵝寶貝名字投票2024年桃園Xpark水族館的結果是：\n",
      "\n",
      "**Tomorin**\n",
      "\n",
      "這隻名為「高松燈」（但在文中提到命名前稱呼該角色名稱時使用了 \" Tomori\"） 的國王企鹅宝贝是在日本动画《BanGDream!It'sMyGO!!!!!》中的一个角色的名字， 因为这个人物曾经前往水族馆看过国鸟，所以以她的名义来给这只小鸭子命名前的投票结果。\n",
      "\n",
      "36 根據資料，嘟胖烏龍茶企鵝寶貝名字投票2024年桃園Xpark水族館的結果是：  **Tomorin**  這隻名為「高松燈」（但在文中提到命名前稱呼該角色名稱時使用了 \" Tomori\"） 的國王企鹅宝贝是在日本动画《BanGDream!It'sMyGO!!!!!》中的一个角色的名字， 因为这个人物曾经前往水族馆看过国鸟，所以以她的名义来给这只小鸭子命名前的投票结果。\n",
      "[Original Question]: 現代人開始注重運動，也因此運動傷害的問題逐漸受到重視，許多人遇到問題時會尋求物理治療師的協助。目前國立臺灣大學物理治療學系的正常修業年限為幾年？\n",
      "\n",
      "\n",
      "[Refined Question]: 國立臺灣大學物理治療學系修業年限\n",
      "\n",
      "[Final Answer]: 根據提供的資料，國立臺灣大學物理治療學系修業年限為四年的日間班制。\n",
      "\n",
      "37 根據提供的資料，國立臺灣大學物理治療學系修業年限為四年的日間班制。\n",
      "[Original Question]: 「呼嘿嘿」是《BanG Dream!》中哪位角色的笑聲習慣？\n",
      "\n",
      "\n",
      "[Refined Question]: BanG Dream! 角色笑聲習慣\n",
      "\n",
      "[Final Answer]: 根據提供的資料，BanG Dream! 角色笑聲習慣如下：\n",
      "\n",
      "* 戶山香澄（Toyama Kasumi）：喜歡用「Kirakira」來形容很多東西，她講話常加一些自我流的情況。\n",
      " \n",
      "這些角色都有自己的獨特的性格和表達方式，讓玩家們能夠更好地了解他們。\n",
      "\n",
      "38 根據提供的資料，BanG Dream! 角色笑聲習慣如下：  * 戶山香澄（Toyama Kasumi）：喜歡用「Kirakira」來形容很多東西，她講話常加一些自我流的情況。   這些角色都有自己的獨特的性格和表達方式，讓玩家們能夠更好地了解他們。\n",
      "[Original Question]: 模壽是中國知名的模型廠商，其旗下的原創漫畫《先祖效應》中出現紅色外觀加上日本武士風格的機體，模壽將之命名為「甲斐之虎」。日本戰國時代被稱為「甲斐之虎」的人物是誰？\n",
      "\n",
      "\n",
      "[Refined Question]: 甲斐之虎日本戰國時代人物是誰\n",
      "\n",
      "[Final Answer]: 甲斐之虎是日本戰國時代人物武田信玄的別稱。\n",
      "\n",
      "39 甲斐之虎是日本戰國時代人物武田信玄的別稱。\n",
      "[Original Question]: 終於到了台灣大學114年度的選課時期，同學們總會在朋友圈流傳各種意義上的好課，可能是「你可以不修，但你一定要請你朋友修」的好課，也可能是「值得一修再修」的好課。剛加入台大的王肥貓同學，正在為選擇通識課而煩惱，想要在他的候選名單選出網路上最多好評的課程。王肥貓的候選名單中有「國民法官必備之基礎鑑識科學」、「現代中國與世界：1911-1979」以及「數位素養導航」。請問依照王肥貓同學的標準，他最有可能去修哪一門課？\n",
      "\n",
      "\n",
      "[Refined Question]: 台大通識課程好評排名\n",
      "\n",
      "[Final Answer]: 根據提供的資料，我們可以看到以下幾個台大通識課程獲得了好評：\n",
      "\n",
      "1. 生物演化與絕滅（魏國彥老師）：這門课對生物學、生態学有興趣的人非常適合，教授溫和且講解清晰。\n",
      "2 北亞草原文化概論 （黃麗生的課程） 這個選修的通識教育是開在平日晚上的，所以不會卡你的時間表。這門课可以讓你了解以前讀過但不知道如何串連與融合的地理和歷史知\n",
      "3 跨越時空談宇宙（陳丕燊老師）：教授學術底蘘濃厚，人格特質又像一個快樂的藝术家，是一位很努力在進行科普教育的人。\n",
      "4 荀子哲学：东亚伦理之基礎 （佐藤将生） 这门课对文化和philosophy有兴趣の人非常適合。教授針對荊子的概念講解得十分詳細，讓你更深刻了解春秋戰國百家爭鳴的時代。\n",
      "5 文字探勘初論（陳建錦老師）：這門課分數很甜，可以輕鬆學習python。\n",
      "\n",
      "以上是根據提供資料所列出的幾個台大通識课程獲得好評。\n",
      "\n",
      "40 根據提供的資料，我們可以看到以下幾個台大通識課程獲得了好評：  1. 生物演化與絕滅（魏國彥老師）：這門课對生物學、生態学有興趣的人非常適合，教授溫和且講解清晰。 2 北亞草原文化概論 （黃麗生的課程） 這個選修的通識教育是開在平日晚上的，所以不會卡你的時間表。這門课可以讓你了解以前讀過但不知道如何串連與融合的地理和歷史知 3 跨越時空談宇宙（陳丕燊老師）：教授學術底蘘濃厚，人格特質又像一個快樂的藝术家，是一位很努力在進行科普教育的人。 4 荀子哲学：东亚伦理之基礎 （佐藤将生） 这门课对文化和philosophy有兴趣の人非常適合。教授針對荊子的概念講解得十分詳細，讓你更深刻了解春秋戰國百家爭鳴的時代。 5 文字探勘初論（陳建錦老師）：這門課分數很甜，可以輕鬆學習python。  以上是根據提供資料所列出的幾個台大通識课程獲得好評。\n",
      "[Original Question]: 《極限體能王SASUKE》是日本TBS電視台不定期播出的運動娛樂特別節目，其身受日本觀眾喜愛，在日本擁有高收視率。《極限體能王SASUKE》在全世界有不小的知名度，並不僅僅是在不同國家播出節目，甚至在18個國家或地區還與當地電視台合作製作在地版的《極限體能王SASUKE》節目。請問2024年的第42回《極限體能王SASUKE》在2024年的哪一天首播？\n",
      "\n",
      "\n",
      "[Refined Question]: 2024年第42回《極限體能王SASUKE》首播日期\n",
      "\n",
      "[Final Answer]: 對不起，我無法提供你想要的資訊，因為我无法訪問抖音百科。\n",
      "\n",
      "41 對不起，我無法提供你想要的資訊，因為我无法訪問抖音百科。\n",
      "[Original Question]: 許多人對原住民族有所誤解，認為原住民部落自古都很排外，然實際上原住民族與外族的接觸很早便有了，甚至也曾出現過漢人擔任部落頭目的故事。請問出身於利嘉部落，後來成為初鹿部落頭目的漢人，名為？\n",
      "\n",
      "\n",
      "[Refined Question]: 出身於利嘉部落，初鹿頭目漢人名字\n",
      "\n",
      "[Final Answer]: 根據提供的資料，出身於利嘉部落、初鹿頭目漢人名字是林貴。\n",
      "\n",
      "42 根據提供的資料，出身於利嘉部落、初鹿頭目漢人名字是林貴。\n",
      "[Original Question]: 《BanG Dream!》是連載於《月刊武士道》的漫畫作品，後來成為了跨媒體發行的大型企劃。《BanG Dream! Ave Mujica》的片頭曲是哪一首？\n",
      "\n",
      "\n",
      "[Refined Question]: BanG Dream! Ave Mujica 片頭曲\n",
      "\n",
      "[Final Answer]: BanG Dream! Ave Mujica 的片頭曲是《KiLL KiSS》，由Diggy-MO’作詞，長谷川大介（SUPALOVE）和 Dig gy - MO' 共同創 作，並 由 長 谷 川 大 伴 編 曲。\n",
      "\n",
      "43 BanG Dream! Ave Mujica 的片頭曲是《KiLL KiSS》，由Diggy-MO’作詞，長谷川大介（SUPALOVE）和 Dig gy - MO' 共同創 作，並 由 長 谷 川 大 伴 編 曲。\n",
      "[Original Question]: Linux作業系統最早於哪一年首次發布？\n",
      "\n",
      "\n",
      "[Refined Question]: Linux作業系統首次發布年份\n",
      "\n",
      "[Final Answer]: Linux作業系統首次發布年份是1991年的10月5日。\n",
      "\n",
      "44 Linux作業系統首次發布年份是1991年的10月5日。\n",
      "[Original Question]: 負責本次作業的助教是來自臺東的卑南族，來自 Likavung 部落，是一個在臺東縣卑南鄉的靜謐之地，近期 Likavung 部落積極復振傳統文化，並於前年興建傳統男子會所「巴拉冠」。請問 Likavung 的中文名稱為何？\n",
      "\n",
      "\n",
      "[Refined Question]: Likavung 部落中文名稱\n",
      "\n",
      "[Final Answer]: 利嘉部落\n",
      "\n",
      "45 利嘉部落\n",
      "[Original Question]: 紅茶是全發酵茶類還是不發酵茶類？\n",
      "\n",
      "\n",
      "[Refined Question]: 紅茶是全發酵還是不发 酶\n",
      "\n",
      "[Final Answer]: 根據提供的資料，紅茶是全發酵。\n",
      "\n",
      "46 根據提供的資料，紅茶是全發酵。\n",
      "[Original Question]: 在《遊戲王》卡牌遊戲中，以「真紅眼黑龍」與「黑魔導」作為融合素材的融合怪獸是什麼？\n",
      "\n",
      "\n",
      "[Refined Question]: 遊戲王真紅眼黑龍 黑魔導融合怪獸\n",
      "\n",
      "[Final Answer]: 根據提供的資料，遊戲王真紅眼黑龍（超魔導竜騎士－ドラグーン・オブレッドアイズ）是一隻融合怪獸卡片。它是由「黒・マジシャン」（Black Magician）的效果和 「true red eyes black dragon」的特殊召喚所產生的。\n",
      "\n",
      "真紅眼黑龍的能力包括：\n",
      "\n",
      "1. 不被指定破壞，不受其他效應影響。\n",
      "2 主要階段可以發動，對方場上一體怪獸會受到傷害，並且該效果只能使用一次每回合\n",
      "3 一次融合作用時，可以將手牌中的通常卡片數量決定能否再進行此操作\n",
      "\n",
      "另外還有另一張真紅眼黑龍的變種版本叫做「超魔導竜騎士－ドラグーン・オブレッドアイズ」，它是由 「黒・マジシャン」（Black Magician）的效果和 、「true red eyes black dragon」的特殊召喚所產生的，並且具有更強大的能力。\n",
      "\n",
      "47 根據提供的資料，遊戲王真紅眼黑龍（超魔導竜騎士－ドラグーン・オブレッドアイズ）是一隻融合怪獸卡片。它是由「黒・マジシャン」（Black Magician）的效果和 「true red eyes black dragon」的特殊召喚所產生的。  真紅眼黑龍的能力包括：  1. 不被指定破壞，不受其他效應影響。 2 主要階段可以發動，對方場上一體怪獸會受到傷害，並且該效果只能使用一次每回合 3 一次融合作用時，可以將手牌中的通常卡片數量決定能否再進行此操作  另外還有另一張真紅眼黑龍的變種版本叫做「超魔導竜騎士－ドラグーン・オブレッドアイズ」，它是由 「黒・マジシャン」（Black Magician）的效果和 、「true red eyes black dragon」的特殊召喚所產生的，並且具有更強大的能力。\n",
      "[Original Question]: 豐田萌繪在《BanG Dream!》企劃中，擔任哪個角色的聲優？\n",
      "\n",
      "\n",
      "[Refined Question]: 豐田萌繪 BanG Dream 角色聲優\n",
      "\n",
      "[Final Answer]: 根據提供的資料，豐田萌繪在 BanG Dream 中飾演了多個角色，但最常見的是以下幾位：\n",
      "\n",
      "1. 松原花音（Poppin'Party）\n",
      "2.? （Afterglow）\n",
      "\n",
      "請注意，這些資訊可能不完整或有誤。\n",
      "\n",
      "48 根據提供的資料，豐田萌繪在 BanG Dream 中飾演了多個角色，但最常見的是以下幾位：  1. 松原花音（Poppin'Party） 2.? （Afterglow）  請注意，這些資訊可能不完整或有誤。\n",
      "[Original Question]: Rugby Union 中，9 號球員的正式名稱為何？\n",
      "\n",
      "\n",
      "[Refined Question]: Rugby Union 9 號球員正式名稱\n",
      "\n",
      "[Final Answer]: 根據提供的資料，Rugby Union 9 號球員正式名稱是 Scrum-half。\n",
      "\n",
      "49 根據提供的資料，Rugby Union 9 號球員正式名稱是 Scrum-half。\n",
      "[Original Question]: 曾被視為太陽系中的行星，最終被降格成矮行星的星球為何？\n",
      "\n",
      "\n",
      "[Refined Question]: 太陽系矮行星原來是哪個\n",
      "\n",
      "[Final Answer]: 根據提供的資料，太陽系矮行星原來是被稱為「小天體」的區域。這個地區位於火 星和木質之間，被認爲是一些未能形成成熟的小球形物体所組成了。\n",
      "\n",
      "然而，在近年来的研究中，我們發現了許多新的信息，例如矮行星的定義、大小與特性等。在2006年的國際天文學聯合會（IAU）的一次大型研討会上，一個名為「小球形物体」的新類別被提出，這些是太陽系中直徑在100公里以上但不夠足以清除其它的小行星的區域。\n",
      "\n",
      "根據這一新的定義，矮 行 星是一種具有特定的大小和軌道條件，但不是完整成熟小球形物体。\n",
      "\n",
      "50 根據提供的資料，太陽系矮行星原來是被稱為「小天體」的區域。這個地區位於火 星和木質之間，被認爲是一些未能形成成熟的小球形物体所組成了。  然而，在近年来的研究中，我們發現了許多新的信息，例如矮行星的定義、大小與特性等。在2006年的國際天文學聯合會（IAU）的一次大型研討会上，一個名為「小球形物体」的新類別被提出，這些是太陽系中直徑在100公里以上但不夠足以清除其它的小行星的區域。  根據這一新的定義，矮 行 星是一種具有特定的大小和軌道條件，但不是完整成熟小球形物体。\n",
      "[Original Question]: 以往政府對動物保護的觀念僅停留在寵物，因此動保法又被調侃為可愛動物保護法，近年來政策逐漸重視野生動物的保護。臺灣最早成立的野生動物救傷單位位於哪個行政區內？\n",
      "\n",
      "\n",
      "[Refined Question]: 臺灣最早成立的野生動物救傷單位位於哪個行政區內？\n",
      "\n",
      "[Final Answer]: 根據資料，臺灣最早成立的野生動物救傷單位是位於集 集大山懷抱中的農業部生物多樣性研究所 野 生 動 物 急 救 站。\n",
      "\n",
      "51 根據資料，臺灣最早成立的野生動物救傷單位是位於集 集大山懷抱中的農業部生物多樣性研究所 野 生 動 物 急 救 站。\n",
      "[Original Question]: 位於南投縣集集鎮的特生中心是親子育樂的好去處，館內以臺灣本土生態及生物為主軸，規劃高、中、低海拔生態系、特有動物、特有植物、環境-生物-人、自然保育、植物的奧秘及動物的奇觀等主題展區。特生中心在2023年改名，目前該單位的名字為？\n",
      "\n",
      "\n",
      "[Refined Question]: 特生中心改名2023年南投縣集集中\n",
      "\n",
      "[Final Answer]: 根據提供的資料，特有生物研究保育中心（Taiwan Endemic Species Research Institute）位於南投縣集集中，是台灣唯一專職於本土特殊稀有的動植物調查、研發和推廣工作單位。\n",
      "\n",
      "52 根據提供的資料，特有生物研究保育中心（Taiwan Endemic Species Research Institute）位於南投縣集集中，是台灣唯一專職於本土特殊稀有的動植物調查、研發和推廣工作單位。\n",
      "[Original Question]: Developing Instruction-Following Speech Language Model Without Speech Instruction-Tuning Data論文中提出的模型是甚麼名字？\n",
      "\n",
      "\n",
      "[Refined Question]: Instruction-Following Speech Language Model Without speech instruction-tuning data model name\n",
      "\n",
      "[Final Answer]: DeSTA2\n",
      "\n",
      "53 DeSTA2\n",
      "[Original Question]: 請問太陽系中體積最大的行星是哪一顆？\n",
      "\n",
      "\n",
      "[Refined Question]: 太陽系中體積最大的行星是哪一顆？\n",
      "\n",
      "[Final Answer]: 太陽系中體積最大的行星是木衛。\n",
      "\n",
      "54 太陽系中體積最大的行星是木衛。\n",
      "[Original Question]: 在語言分類學上，臺灣目前法定的十六個原住民族語言皆屬於南島語系，然其中一族的語言與其他語言在分類學上一般不被視為同一群，請問是哪一族的語言與其他語言親緣關係最遙遠？\n",
      "\n",
      "\n",
      "[Refined Question]: 臺灣原住民族語言親緣關係最遙遠的族群\n",
      "\n",
      "[Final Answer]: 根據提供的資料，臺灣原住民族語言親緣關係最遙遠的是馬達加斯卡島上的南岛族群。\n",
      "\n",
      "55 根據提供的資料，臺灣原住民族語言親緣關係最遙遠的是馬達加斯卡島上的南岛族群。\n",
      "[Original Question]: 相傳在台灣大學的某一堂程式設計課程從來不會進行分組，如果有人問為甚麼沒有分組，老師總會說「我上課都不分組的。分組的結果通常都是一個阿宅在寫code；一個未來可以當PM的在台上吹牛；一個廢柴跑去買便當」。請問講出這句話的老師是誰？\n",
      "\n",
      "\n",
      "[Refined Question]: 台大程式設計課老師名言\n",
      "\n",
      "[Final Answer]: 根據提供的資料，台大程式設計課老師張傑帆有以下名言：\n",
      "\n",
      "1. \"用一種方法，最好是只有一种方式来做事。\"\n",
      "2.\"优雅、明确和简单\" 是 Python 设计哲学。\n",
      "3.“優秀的人不會因為自己不知道而害怕問問題。”\n",
      "\n",
      "56 根據提供的資料，台大程式設計課老師張傑帆有以下名言：  1. \"用一種方法，最好是只有一种方式来做事。\" 2.\"优雅、明确和简单\" 是 Python 设计哲学。 3.“優秀的人不會因為自己不知道而害怕問問題。”\n",
      "[Original Question]: 臺灣原住民族的語言非常多元，有各式各樣的打招呼用語，比方說布農族的「uninang mihumisang」、阿美族的「nga'ay ho」。「embiyax namu kana」 是哪一臺灣原住民族的打招呼用語？\n",
      "\n",
      "\n",
      "[Refined Question]: embiyax namu kana 原住民族打招呼用語\n",
      "\n",
      "[Final Answer]: 根據提供的資料，太魯閣族語中「embiyax namu kana」是原住民族打招呼用语。\n",
      "\n",
      "57 根據提供的資料，太魯閣族語中「embiyax namu kana」是原住民族打招呼用语。\n",
      "[Original Question]: 鄒族與布農族生活區域大量重疊，最開始鄒族因為驍勇善戰，因此擁有大量土地，後來因為外族人帶來的瘟疫，使得鄒族的族群勢力快速下滑，並與布農族人混居。請問「鄒與布農，永久美麗」這句話與哪個鄒族、布農族混居的部落息息相關？\n",
      "\n",
      "\n",
      "[Refined Question]: 鄒族布農混居部落永久美麗\n",
      "\n",
      "[Final Answer]: 根據提供的資料，久美國小是一所位於南投縣信義鄉的小學，它是全國唯一實施鄒與布農兩族文化共生的學校。該校以祭典為核心架構，並設計螺旋式相關子課程，以培育出兼具民族 culture 與世界公民素養的久美兒童。\n",
      "\n",
      "永久屋Lalauya楓紅社區是由嘉義縣政府與阿里山鄉共同推動，於2012年12月落成啟用。該村共有46棠房屋，是一座真正離災不离 village 的地方，並且提供了安置受灾戶的永久性住所。\n",
      "\n",
      "在這兩個案例中，都表現出對原民文化和傳統祭典之重視，以及推動民族實驗教育與社區發展。\n",
      "\n",
      "58 根據提供的資料，久美國小是一所位於南投縣信義鄉的小學，它是全國唯一實施鄒與布農兩族文化共生的學校。該校以祭典為核心架構，並設計螺旋式相關子課程，以培育出兼具民族 culture 與世界公民素養的久美兒童。  永久屋Lalauya楓紅社區是由嘉義縣政府與阿里山鄉共同推動，於2012年12月落成啟用。該村共有46棠房屋，是一座真正離災不离 village 的地方，並且提供了安置受灾戶的永久性住所。  在這兩個案例中，都表現出對原民文化和傳統祭典之重視，以及推動民族實驗教育與社區發展。\n",
      "[Original Question]: 動畫「雖然是公會的櫃檯小姐，但因為不想加班所以打算獨自討伐迷宮頭目」中女主角隱藏的冒險者身份是甚麼？\n",
      "\n",
      "\n",
      "[Refined Question]: 動畫女主角隱藏冒險者身份迷宮頭目\n",
      "\n",
      "[Final Answer]: 動畫女主角亞莉納（Ariana）隱藏冒險者身份，迷宮頭目是她在公會工作之外的另一個身分。\n",
      "\n",
      "59 動畫女主角亞莉納（Ariana）隱藏冒險者身份，迷宮頭目是她在公會工作之外的另一個身分。\n",
      "[Original Question]: 在卑南族的傳說中，有一對姊弟（Tuku 及 Sihasihau），這對姊弟後來各自創建了一個部落，其中姊姊 Tuku 後來創建了哪一個部落？\n",
      "\n",
      "\n",
      "[Refined Question]: Tuku 姊姊 卑南族 部落\n",
      "\n",
      "[Final Answer]: 根據提供的資料，Tuku 是射馬干部落創社人的祖先，他是卡大地布社會西哈希浩（Sihasihau）的姊妹。\n",
      "\n",
      "60 根據提供的資料，Tuku 是射馬干部落創社人的祖先，他是卡大地布社會西哈希浩（Sihasihau）的姊妹。\n",
      "[Original Question]: 2005 播出的電視劇《終極一班》中，有一個高中生戰力排行榜，稱為「KO榜」，該榜榜首為？\n",
      "\n",
      "\n",
      "[Refined Question]: 終極一班 KO榜首 2005年電視劇\n",
      "\n",
      "[Final Answer]: 根據資料，終極一班 KO榜首是田弘光，他的戰力指數為 12000。\n",
      "\n",
      "61 根據資料，終極一班 KO榜首是田弘光，他的戰力指數為 12000。\n",
      "[Original Question]: Linux kernel 曾使用的 process scheduler --- completely fair scheduler (CFS) 採用了何種資料結構來儲存排程相關資訊？\n",
      "\n",
      "\n",
      "[Refined Question]: completely fair scheduler (CFS) data structure\n",
      "\n",
      "[Final Answer]: 根據提供的相關資料，Completely Fair Scheduler (CFS) 使用 Red-Black Tree 資料結構（self-balancing binary search tree）來存放可執行任務。每個節點代表一個可以運作中的工作，並且按照虛擬時間 (_vruntime_) 進行動的順序進行排序。\n",
      "\n",
      "在 C FS 中，每當有時鐘中斷或上下文切換發生，系統會選取具有最低 _vruntime_ 的任務來執行。這樣可以確保每個工作都得到公平分配 CPU 時間，並且能夠有效地管理多工環境下的資源配置。\n",
      "\n",
      "以下是 CFS 資料結構的簡要概述：\n",
      "\n",
      "*   使用 Red-Black Tree 類型資料庫\n",
      "    * 每一個節點代表可執行任務（task）\n",
      "        + 按照虛擬時間 (_vruntime_) 進行動順序進行排序\n",
      "\n",
      "這種設計使得 CFS 能夠有效地管理多工環境下的資源配置，並且能確保每個工作都得到公平分配 CPU 時間。\n",
      "\n",
      "62 根據提供的相關資料，Completely Fair Scheduler (CFS) 使用 Red-Black Tree 資料結構（self-balancing binary search tree）來存放可執行任務。每個節點代表一個可以運作中的工作，並且按照虛擬時間 (_vruntime_) 進行動的順序進行排序。  在 C FS 中，每當有時鐘中斷或上下文切換發生，系統會選取具有最低 _vruntime_ 的任務來執行。這樣可以確保每個工作都得到公平分配 CPU 時間，並且能夠有效地管理多工環境下的資源配置。  以下是 CFS 資料結構的簡要概述：  *   使用 Red-Black Tree 類型資料庫     * 每一個節點代表可執行任務（task）         + 按照虛擬時間 (_vruntime_) 進行動順序進行排序  這種設計使得 CFS 能夠有效地管理多工環境下的資源配置，並且能確保每個工作都得到公平分配 CPU 時間。\n",
      "[Original Question]: 請問第二次世界大戰中，盟軍在歐洲發動的最大規模登陸作戰諾曼第登陸（Normandy Landings），其作戰代號為何？\n",
      "\n",
      "\n",
      "[Refined Question]: 諾曼第登陸作戰代號\n",
      "\n",
      "[Final Answer]: 霸王行動（Operation Overlord）\n",
      "\n",
      "63 霸王行動（Operation Overlord）\n",
      "[Original Question]: 《Cytus II》遊戲中「Body Talk」是哪位角色的歌曲？\n",
      "\n",
      "\n",
      "[Refined Question]: Cytus II Body Talk song\n",
      "\n",
      "[Final Answer]: 根據提供的資料，Cytus II Body Talk 的歌曲由 M2U sáng tác，並且發布於 2018 年。這首單 曲可以在 Apple Music 上找到，也有其他版本可供下載和播放。\n",
      "\n",
      "以下是相關資訊：\n",
      "\n",
      "* 歌名：BodyTalk\n",
      "* 表演者:M2u \n",
      " * 發佈日期:12 July,2020\n",
      "\n",
      "64 根據提供的資料，Cytus II Body Talk 的歌曲由 M2U sáng tác，並且發布於 2018 年。這首單 曲可以在 Apple Music 上找到，也有其他版本可供下載和播放。  以下是相關資訊：  * 歌名：BodyTalk * 表演者:M2u   * 發佈日期:12 July,2020\n",
      "[Original Question]: 李琳山教授 1974 年畢業於國立臺灣大學電機工程學系，並且在 1975 年及 1977 年由美國史丹佛大學取得電機工程碩士及博士學位。他在國立臺灣大學所開設的信號與系統課程，在期末考前後會有一次演講，該演講又被稱為？\n",
      "\n",
      "\n",
      "[Refined Question]: 李琳山教授信號與系統課程演講名稱\n",
      "\n",
      "[Final Answer]: 李琳山教授的信號與系統課程演講名稱為 \" 信号与系统\" (Signals and Systems )。\n",
      "\n",
      "65 李琳山教授的信號與系統課程演講名稱為 \" 信号与系统\" (Signals and Systems )。\n",
      "[Original Question]: 唉，我朋友總是一直說他很窮，買不起輝達最新的 5090 顯卡。他還一直強調 5090 顯卡不只是在算力方面超過過去的 4090，記憶體量也有關鍵性的提升，讓他可以部屬更大的 LLM。那 RTX 5090 的 VRAM 到底是多大？\n",
      "\n",
      "\n",
      "[Refined Question]: RTX 5090 VRAM size\n",
      "\n",
      "[Final Answer]: 根據 Search result 2 的資料，NVIDIA GeForce RTX5090的VRAM大小為32GB。\n",
      "\n",
      "66 根據 Search result 2 的資料，NVIDIA GeForce RTX5090的VRAM大小為32GB。\n",
      "[Original Question]: 棒球一直是風靡全台灣的運動之一，台灣棒球歷史也相當的悠久，自日治時期的台灣開始便有棒球運動的紀錄。而中華職棒作為台灣目前唯一的職業棒球聯盟，更是台灣棒球的重要象徵之一。台灣的棒球也享譽國際，是各大棒球國際賽的常客之一。請問在2024年所舉辦的「世界棒球12強賽」中，冠軍為哪一隊？\n",
      "\n",
      "\n",
      "[Refined Question]: 2024年世界棒球12強賽冠軍隊伍\n",
      "\n",
      "[Final Answer]: 根據資料，2024年世界棒球12強賽冠軍隊伍是中華台北。\n",
      "\n",
      "67 根據資料，2024年世界棒球12強賽冠軍隊伍是中華台北。\n",
      "[Original Question]: 中國四大奇書是哪幾本？\n",
      "\n",
      "\n",
      "[Refined Question]: 中國四大奇書名單\n",
      "\n",
      "[Final Answer]: 根據提供的資料，中國四大奇書名單是：\n",
      "\n",
      "1. 《水滸傳》\n",
      "2._三國演義》_\n",
      "3..《西遊記 》\n",
      "4 ._金瓶梅\n",
      "\n",
      "68 根據提供的資料，中國四大奇書名單是：  1. 《水滸傳》 2._三國演義》_ 3..《西遊記 》 4 ._金瓶梅\n",
      "[Original Question]: 中國時辰中的子時，如果用24小時制表示，是幾點到幾點？\n",
      "\n",
      "\n",
      "[Refined Question]: 子時 24 小时制時間範圍是幾點到几点？\n",
      "\n",
      "[Final Answer]: 根據提供的資料，子時在 24 小时制時間範圍是從23點到1点。\n",
      "\n",
      "69 根據提供的資料，子時在 24 小时制時間範圍是從23點到1点。\n",
      "[Original Question]: 一般學生總是有許多課堂作業需要完成，通常學生們會順著作業的死線將時序拉近，因為遲交作業可能讓作業不算分或是作業分數打折。而電腦也不例外，電腦有著排程演算法來決定接下來要執行什麼動作。請問在作業系統中，避免要錯過時限來完成作業的排程演算法稱為什麼？\n",
      "\n",
      "\n",
      "[Refined Question]: 避免錯過時限的排程演算法在作業系統中稱為什麼\n",
      "\n",
      "[Final Answer]: 根據提供的資料，避免錯過時限（Deadline）的排程演算法在作業系統中稱為Real-Time Scheduling。\n",
      "\n",
      "70 根據提供的資料，避免錯過時限（Deadline）的排程演算法在作業系統中稱為Real-Time Scheduling。\n",
      "[Original Question]: 在2010年代初期由日本輕小說改編的知名動畫系列《刀劍神域》中，存在一組以英文字母「C」開頭搭配四位數「8763」構成的招式代號，此招式因施展時會出現十六道連續斬擊軌跡與金色光效而廣為觀眾所知。請具體回答：該代號「C8763」在原作中明確對應哪位角色持有的劍技？\n",
      "\n",
      "\n",
      "[Refined Question]: 刀劍神域 C8763 招式代號對應角色\n",
      "\n",
      "[Final Answer]: 根據提供的資料，C8763 是刀劍神域中桐人使用的一招式代號。\n",
      "\n",
      "71 根據提供的資料，C8763 是刀劍神域中桐人使用的一招式代號。\n",
      "[Original Question]: 曾經風靡一時的影集《斯卡羅》描述的是斯卡羅族的故事，劇中之地名「柴城」位於現今的哪個行政區劃？\n",
      "\n",
      "\n",
      "[Refined Question]: 斯卡羅族柴城地名現今行政區劃\n",
      "\n",
      "[Final Answer]: 根據資料，斯卡羅族柴城地名現今行政區劃為屏東車市。\n",
      "\n",
      "72 根據資料，斯卡羅族柴城地名現今行政區劃為屏東車市。\n",
      "[Original Question]: Google Colab的訂閱制中，若要使用A100高級GPU，需要訂閱「Colab Pro」還是「Colab Pro+」？\n",
      "\n",
      "\n",
      "[Refined Question]: Colab Pro vs Colad pro+\n",
      "\n",
      "[Final Answer]: 根據提供的資料，我們可以看到 Colab Pro 和Colad pro+ 的主要差異如下：\n",
      "\n",
      "*   **Compute Units**： \n",
      "    * \t-ColaborPro:100computeunits\n",
      "     -colap+:500 compute units（含有pro中的计算单元）\n",
      "    \n",
      "      這意味著，使用者在選擇 colabad + 時，可以獲得更多的計算單位，這將使他們能夠執行更複雜和耗時較長的大型機器學習模型。\n",
      "*   **GPU Access**： \n",
      "    * \t-ColaborPro:提供額外強大的 GPU 變成\n",
      "     -colap+:同樣也會有更多的gpu變身\n",
      "\n",
      "      這意味著，使用者在選擇 colabad + 時，可以獲得更好的硬體支持，這將使他們能夠執行需要大量計算能力的大型機器學習模型。\n",
      "*   **Background Execution**： \n",
      "    * \t-ColaborPro:無法背景運作\n",
      "     -colap+:可以進行長時間的後台工作\n",
      "\n",
      "      這意味著，使用者在選擇 colabad + 時，可以執行需要較久才能完成的大型機器學習模型，而不會影響到他們正在做的事情。\n",
      "*   **AI Assistance**： \n",
      "    * \t-ColaborPro:提供 AI 助手\n",
      "     -colap+:同樣也可以使用ai助理\n",
      "\n",
      "      這意味著，選擇 colabad + 的用戶，可以獲得更好的輔導和支援，這將使他們能夠更加高效地完成工作。\n",
      "\n",
      "綜上所述，我們看到 Colab Pro 和Colad pro+ 都提供了強大的計算能力、GPU 變身以及背景運作功能，但是選擇 colabad + 可以得到更多的資源，包括額外 400 個 Compute Units，以及更好的硬體支持和 AI 助手。\n",
      "\n",
      "73 根據提供的資料，我們可以看到 Colab Pro 和Colad pro+ 的主要差異如下：  *   **Compute Units**：      * \t-ColaborPro:100computeunits      -colap+:500 compute units（含有pro中的计算单元）            這意味著，使用者在選擇 colabad + 時，可以獲得更多的計算單位，這將使他們能夠執行更複雜和耗時較長的大型機器學習模型。 *   **GPU Access**：      * \t-ColaborPro:提供額外強大的 GPU 變成      -colap+:同樣也會有更多的gpu變身        這意味著，使用者在選擇 colabad + 時，可以獲得更好的硬體支持，這將使他們能夠執行需要大量計算能力的大型機器學習模型。 *   **Background Execution**：      * \t-ColaborPro:無法背景運作      -colap+:可以進行長時間的後台工作        這意味著，使用者在選擇 colabad + 時，可以執行需要較久才能完成的大型機器學習模型，而不會影響到他們正在做的事情。 *   **AI Assistance**：      * \t-ColaborPro:提供 AI 助手      -colap+:同樣也可以使用ai助理        這意味著，選擇 colabad + 的用戶，可以獲得更好的輔導和支援，這將使他們能夠更加高效地完成工作。  綜上所述，我們看到 Colab Pro 和Colad pro+ 都提供了強大的計算能力、GPU 變身以及背景運作功能，但是選擇 colabad + 可以得到更多的資源，包括額外 400 個 Compute Units，以及更好的硬體支持和 AI 助手。\n",
      "[Original Question]: 台灣大學中由李宏毅老師開設的機器學習，是屬於哪個學院的課程？\n",
      "\n",
      "\n",
      "[Refined Question]: 李宏毅老師機器學習課程學院\n",
      "\n",
      "[Final Answer]: 根據提供的資料，李宏毅老師（Hung-yi Lee）開設了多個機器學習課程學院。以下是其中一些資訊：\n",
      "\n",
      "1. **國立台湾大学：机制学习-CS自学指南** - 李先生為本書撰寫了一份CS(self-learning)的教材，涵蓋必須工具、日常工作流和實用箱等內容。\n",
      "2. 2024春季课程《Introduction to Generative AI》- 这是李宏毅老師在台湾大学开设的一门关于生成式人工智能（GeneraiveAI）的課程，涵盖了从基本概念到大型语言模型的训练和应用等內容。\n",
      "3. GitHub上的课程资料 - 李先生也将他的机器学习课件及作业上传到了GitHub上，可以供学生下载使用。\n",
      "\n",
      "因此，我們可以得出结论：李宏毅老師開設了多個機械學習課程學院，涵蓋從基本工具到大型語言模型的訓練和應用等內容。\n",
      "\n",
      "74 根據提供的資料，李宏毅老師（Hung-yi Lee）開設了多個機器學習課程學院。以下是其中一些資訊：  1. **國立台湾大学：机制学习-CS自学指南** - 李先生為本書撰寫了一份CS(self-learning)的教材，涵蓋必須工具、日常工作流和實用箱等內容。 2. 2024春季课程《Introduction to Generative AI》- 这是李宏毅老師在台湾大学开设的一门关于生成式人工智能（GeneraiveAI）的課程，涵盖了从基本概念到大型语言模型的训练和应用等內容。 3. GitHub上的课程资料 - 李先生也将他的机器学习课件及作业上传到了GitHub上，可以供学生下载使用。  因此，我們可以得出结论：李宏毅老師開設了多個機械學習課程學院，涵蓋從基本工具到大型語言模型的訓練和應用等內容。\n",
      "[Original Question]: 就讀國立臺灣大學資工系的雪江同學，正在為 113 學年度第 2 學期選課的事情煩惱著，身為一位大三學生，他正在考慮兩個修課的策略。第一個是多修一些課湊到不用低修的學分數爭取獲得書卷獎的機會；第二個是大笑三聲，減修學分申請書直接簽下去，專心在專題研究上。如果雪江同學選擇第一個策略，它至少要修多少學分才可以不用簽減修學分申請書？\n",
      "\n",
      "\n",
      "[Refined Question]: ['國立臺灣大學資工系 113 學年度第2學期選課策略']\n",
      "\n",
      "[Final Answer]: 根據提供的資料，我們可以得知國立臺灣大學資工系 113 學年度第2學期選課策略如下：\n",
      "\n",
      "1. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。\n",
      "   - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。\n",
      "\n",
      "2. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。\n",
      "   - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。\n",
      "\n",
      "3. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。\n",
      "   - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。\n",
      "\n",
      "4. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。\n",
      "   - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。\n",
      "\n",
      "5. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。\n",
      "   - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。\n",
      "\n",
      "6. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。\n",
      "   - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。\n",
      "\n",
      "7. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。\n",
      "   - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。\n",
      "\n",
      "8. 選修「教育方法」或其他相關\n",
      "\n",
      "75 根據提供的資料，我們可以得知國立臺灣大學資工系 113 學年度第2學期選課策略如下：  1. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。    - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。  2. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。    - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。  3. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。    - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。  4. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。    - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。  5. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。    - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。  6. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。    - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。  7. 選修「教育方法」或其他相關科目前，需先完成至少一門教材基礎、數理基本能力等必須之核心主題。    - 必要的主要是師資生需要在入学即开始学习师资课程，并且必须通过相关考试。  8. 選修「教育方法」或其他相關\n",
      "[Original Question]: 知名 AI VTuber「Neuro-sama」最初的 Live2D 模型是使用 VTube Studio 的哪個角色？\n",
      "\n",
      "\n",
      "[Refined Question]: Neuro-sama VTube Studio Live2D 模型角色\n",
      "\n",
      "[Final Answer]: 根據提供的資料，Neuro-sama 是一個使用 VTube Studio 和 Live2D 模型角色進行直播和互動的人工智慧虛擬主播。\n",
      "\n",
      "76 根據提供的資料，Neuro-sama 是一個使用 VTube Studio 和 Live2D 模型角色進行直播和互動的人工智慧虛擬主播。\n",
      "[Original Question]: 「Re：從零開始的異世界生活 第三季」動畫中，劫持愛蜜莉雅並想取其為妻的人是誰？\n",
      "\n",
      "\n",
      "[Refined Question]: Re：從零開始的異世界生活 第三季 愛蜜莉雅劫持者\n",
      "\n",
      "[Final Answer]: 根據提供的資料，愛蜜莉雅劫持者的身份是雷古勒斯·科爾尼亞司（Re:ゼロから始める異世界生活第三季第12話）。他是一個具有強大權能的人物，可以控制和操縱別人的心臟。\n",
      "\n",
      "77 根據提供的資料，愛蜜莉雅劫持者的身份是雷古勒斯·科爾尼亞司（Re:ゼロから始める異世界生活第三季第12話）。他是一個具有強大權能的人物，可以控制和操縱別人的心臟。\n",
      "[Original Question]: 《海綿寶寶》的主角海綿寶寶在第五季《失蹤記》中，在哪個城市擊敗刺破泡泡紅眼幫？\n",
      "\n",
      "\n",
      "[Refined Question]: 海綿寶宝失蹤記城市擊敗刺破泡bubble buddy season 5 city defeat Red Eye Gang\n",
      "\n",
      "[Final Answer]: 根據提供的資料，我們可以看到相關關鍵詞如下：\n",
      "\n",
      "* 海綿寶宝 (SpongeBob SquarePants)\n",
      "  * lost記錄：失蹤\n",
      "    - season5: 第五季\n",
      "\n",
      "城市擊敗刺破泡bubble buddy Red Eye Gang 的內容可能與海维的某一集有所相關。\n",
      "\n",
      "78 根據提供的資料，我們可以看到相關關鍵詞如下：  * 海綿寶宝 (SpongeBob SquarePants)   * lost記錄：失蹤     - season5: 第五季  城市擊敗刺破泡bubble buddy Red Eye Gang 的內容可能與海维的某一集有所相關。\n",
      "[Original Question]: 玉米是單子葉還是雙子葉植物？\n",
      "\n",
      "\n",
      "[Refined Question]: 玉米是單子葉還是不雙子的植物\n",
      "\n",
      "[Final Answer]: 根據提供的資料，玉米屬於單子葉植物。\n",
      "\n",
      "79 根據提供的資料，玉米屬於單子葉植物。\n",
      "[Original Question]: 中華民國陸軍，隸屬於國防部陸軍司令部，總兵力約為13.2萬，兵力為三軍之最。請問中華民國陸軍軍歌前六字為何？\n",
      "\n",
      "\n",
      "[Refined Question]: 中華民國陸軍 軍歌 前六字\n",
      "\n",
      "[Final Answer]: 根據提供的資料，中華民國陸軍 軍歌 前六字是：\n",
      "\n",
      "\"風雲起,山河動\"\n",
      "\n",
      "這些詞句出自《陆军军(song)》 的 歌词 原文。\n",
      "\n",
      "80 根據提供的資料，中華民國陸軍 軍歌 前六字是：  \"風雲起,山河動\"  這些詞句出自《陆军军(song)》 的 歌词 原文。\n",
      "[Original Question]: 台大的理工科系大多規定一些基礎自然科學科目，如普通物理和普通化學，作為必修學分，這似乎已成為「普通」跟「理所當然」的規定。但同時也有一些科系，由於科系的專業幾乎並無這些自然科學知識的用武之地，因此便將這些科目的必修學分要求較為放寬。請問台大電資學院哪個系規定物理、化學以及生物科目可以只擇一修習即可？\n",
      "\n",
      "\n",
      "[Refined Question]: 台大電資學院哪個系物理化學生物科目只需選一修習\n",
      "\n",
      "[Final Answer]: 根據提供的資料，台大電資學院有多個系，但並沒有明確指出哪一個科目只需選一修習。然而，我們可以看到一些相關信息：\n",
      "\n",
      "* 電機工程學士班：通常需要考取數甲、物理和化工等幾門課程。\n",
      "* 資訊與通信研究所碩博組（資通所）：一般會要求研究生在入学前完成微積分、高級線性代数，計算机概论以及電機工程學士班的基本科目，如數甲、物理和化工等。\n",
      "\n",
      "然而，這些信息並不完全確定哪個系只需選一修習。\n",
      "\n",
      "81 根據提供的資料，台大電資學院有多個系，但並沒有明確指出哪一個科目只需選一修習。然而，我們可以看到一些相關信息：  * 電機工程學士班：通常需要考取數甲、物理和化工等幾門課程。 * 資訊與通信研究所碩博組（資通所）：一般會要求研究生在入学前完成微積分、高級線性代数，計算机概论以及電機工程學士班的基本科目，如數甲、物理和化工等。  然而，這些信息並不完全確定哪個系只需選一修習。\n",
      "[Original Question]: 在月球的火山地形中，廣大而平坦的玄武岩平原地形被稱為月海、月灣或月湖。憂傷湖（Lacus Doloris）、死湖（Lacus Mortis）、忘湖（Lacus Oblivionis）、恐怖湖（Lacus Timoris）以及愛灣（Sinus Amoris），以上五個地形何者位於不面對地球的月球背面？\n",
      "\n",
      "\n",
      "[Refined Question]: 月球背面地形名單\n",
      "\n",
      "[Final Answer]: 根據提供的資料，月球背面的地形名單如下：\n",
      "\n",
      "1. 南極艾特肯盆（SouthPole-Aitken Basin）\n",
      "2.Altai Vallis\n",
      "3.Baade Valley \n",
      "4.VallisBohr\n",
      "\n",
      "82 根據提供的資料，月球背面的地形名單如下：  1. 南極艾特肯盆（SouthPole-Aitken Basin） 2.Altai Vallis 3.Baade Valley  4.VallisBohr\n",
      "[Original Question]: 請問由貝多芬所創作的《C♯小調第14號鋼琴奏鳴曲》，其較為人知的別稱是什麼？\n",
      "\n",
      "\n",
      "[Refined Question]: 貝多芬 C♯小調第14號鋼琴奏鳴曲 別稱\n",
      "\n",
      "[Final Answer]: 貝多芬 C♯小調第14號鋼琴奏鳴曲 別稱為「月光」或 「Mondscheinsonate」。\n",
      "\n",
      "83 貝多芬 C♯小調第14號鋼琴奏鳴曲 別稱為「月光」或 「Mondscheinsonate」。\n",
      "[Original Question]: 阿米斯音樂節是在國際上頗負盛名的音樂展演活動，請問阿米斯音樂節是由哪位歌手所舉辦？\n",
      "\n",
      "\n",
      "[Refined Question]: 阿米斯音樂節由哪位歌手舉辦\n",
      "\n",
      "[Final Answer]: 阿米斯音樂節由舒美恩（Suming）舉辦。\n",
      "\n",
      "84 阿米斯音樂節由舒美恩（Suming）舉辦。\n",
      "[Original Question]: 「Poppy Playtime - Chapter 4」遊戲中出現的黏土人叫甚麼名字？\n",
      "\n",
      "\n",
      "[Refined Question]: Poppy Playtime Chapter 4黏土人名字\n",
      "\n",
      "[Final Answer]: 根據提供的資料，Poppy Playtime Chapter 4黏土人名字是Doey the Doughman。\n",
      "\n",
      "85 根據提供的資料，Poppy Playtime Chapter 4黏土人名字是Doey the Doughman。\n",
      "[Original Question]: 賓茂部落 Djumulj 的現址是 1951 年遷村後的新聚落，Djumulj 在排灣族語裡是「經常豐收，糧食堆積如山之地」的意思。賓茂村是一塊飛地。在地理位置上，賓茂被太麻里鄉所包圍，但賓茂其實屬於何一行政區劃？\n",
      "\n",
      "\n",
      "[Refined Question]: 賓茂部落 Djumulj 排灣族語意思 太麻里鄉行政區劃\n",
      "\n",
      "[Final Answer]: 根據提供的資料，我們可以回答以下問題：\n",
      "\n",
      "1. 賓茂部落 Djumulj 排灣族語意思：\n",
      "賑茲穆爾（Dhulum）在排湾语中是「經常豐收，糧食堆積如山之地」的意義。\n",
      "\n",
      "2 太麻里鄉行政區劃：\n",
      "\n",
      "太馬里的九個村包括：美和、北三合、三好、大王、新香蘭及金崙等。\n",
      "\n",
      "86 根據提供的資料，我們可以回答以下問題：  1. 賓茂部落 Djumulj 排灣族語意思： 賑茲穆爾（Dhulum）在排湾语中是「經常豐收，糧食堆積如山之地」的意義。  2 太麻里鄉行政區劃：  太馬里的九個村包括：美和、北三合、三好、大王、新香蘭及金崙等。\n",
      "[Original Question]: 義大利文藝復興時期著名雕塑家米開朗基羅創作的《大衛》雕像，最初是在何處雕刻並展現其雕塑藝術成就？\n",
      "\n",
      "\n",
      "[Refined Question]: 米開朗基羅《大衛》雕像創作地點\n",
      "\n",
      "[Final Answer]: 根據提供的資料，米開朗基羅《大衛》雕像創作地點是佛罗伦萨（意大利）。\n",
      "\n",
      "87 根據提供的資料，米開朗基羅《大衛》雕像創作地點是佛罗伦萨（意大利）。\n",
      "[Original Question]: 中華民國國軍的軍階中，最高級的將領為特級上將，肩、領章上有五顆星星。除了蔣中正之外，另一位曾短暫晉升特級上將的將領是誰？\n",
      "\n",
      "\n",
      "[Refined Question]: 中華民國特級上將第二位\n",
      "\n",
      "[Final Answer]: 根據資料，中華民國特級上將第二位是李烈钧，但他並不是直接晉升為二级或一级的，而是在審判西安事變的一般一軍統帥張學良時，因高層军階不得低於被告人的阶次，加了「」(即加了一個特級上將)\n",
      "\n",
      "88 根據資料，中華民國特級上將第二位是李烈钧，但他並不是直接晉升為二级或一级的，而是在審判西安事變的一般一軍統帥張學良時，因高層军階不得低於被告人的阶次，加了「」(即加了一個特級上將)\n",
      "[Original Question]: 線上遊戲「英雄聯盟」2012年第二賽季世界大賽的總冠軍是哪一個戰隊？\n",
      "\n",
      "\n",
      "[Refined Question]: 英雄聯盟 2012年第二賽季世界大赛冠军战队\n",
      "\n",
      "[Final Answer]: 台北暗杀星（Taipei Assassins，简称TPA）\n",
      "\n",
      "89 台北暗杀星（Taipei Assassins，简称TPA）\n",
      "[Original Question]: 在日本麻將中，非莊家一開始的手牌有幾張？\n",
      "\n",
      "\n",
      "[Refined Question]: 日本麻將非莊家手牌張數\n",
      "\n",
      "[Final Answer]: 根據日本麻將規則，非莊家手牌張數通常為14张。\n",
      "\n",
      "90 根據日本麻將規則，非莊家手牌張數通常為14张。\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Fill in your student ID first.\n",
    "STUDENT_ID = \"B12901148\"\n",
    "\n",
    "STUDENT_ID = STUDENT_ID.lower()\n",
    "with open('./public.txt', 'r') as input_f:\n",
    "    questions = input_f.readlines()\n",
    "    questions = [l.strip().split(',')[0] for l in questions]\n",
    "    for id, question in enumerate(questions, 1):\n",
    "        if Path(f\"./{STUDENT_ID}_{id}.txt\").exists():\n",
    "            continue\n",
    "        answer = await pipeline(question)\n",
    "        answer = answer.replace('\\n',' ')\n",
    "        print(id, answer)\n",
    "        with open(f'./{STUDENT_ID}_{id}.txt', 'w') as output_f:\n",
    "            print(answer, file=output_f)\n",
    "\n",
    "with open('./private.txt', 'r') as input_f:\n",
    "    questions = input_f.readlines()\n",
    "    for id, question in enumerate(questions, 31):\n",
    "        if Path(f\"./{STUDENT_ID}_{id}.txt\").exists():\n",
    "            continue\n",
    "        answer = await pipeline(question)\n",
    "        answer = answer.replace('\\n',' ')\n",
    "        print(id, answer)\n",
    "        with open(f'./{STUDENT_ID}_{id}.txt', 'a') as output_f:\n",
    "            print(answer, file=output_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3157d041",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-19T17:11:54.203287Z",
     "iopub.status.busy": "2025-03-19T17:11:54.203019Z",
     "iopub.status.idle": "2025-03-19T17:11:54.209739Z",
     "shell.execute_reply": "2025-03-19T17:11:54.209103Z"
    },
    "id": "GmLO9PlmEBPn",
    "papermill": {
     "duration": 0.033449,
     "end_time": "2025-03-19T17:11:54.210836",
     "exception": false,
     "start_time": "2025-03-19T17:11:54.177387",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Combine the results into one file.\n",
    "with open(f'./{STUDENT_ID}.txt', 'w') as output_f:\n",
    "    for id in range(1,91):\n",
    "        with open(f'./{STUDENT_ID}_{id}.txt', 'r') as input_f:\n",
    "            answer = input_f.readline().strip()\n",
    "            print(answer, file=output_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0269e6ea",
   "metadata": {
    "papermill": {
     "duration": 0.025176,
     "end_time": "2025-03-19T17:11:54.260925",
     "exception": false,
     "start_time": "2025-03-19T17:11:54.235749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1801.089512,
   "end_time": "2025-03-19T17:11:57.006779",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-19T16:41:55.917267",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
